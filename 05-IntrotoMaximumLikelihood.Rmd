
# Introduction to MLE {#mle}

This section will provide an overview of MLE. There are a few general connections we can make between the things we know (the linear least squares model) and the concepts introduced here.

  - Practical Uses: Going from nice continuous outcome data to outcome data generated differently
  - Estimation: Going from minimizing squared error to maximizing likelihood. 
      + Both involve optimization. In likelihood, we are trying to find the optimal values of parameters for a distribution given observed data.
  - Formulation: Going from Linear Model to Generalized Linear Model
  - Mechanics in R: Going from `lm()` to `glm()` and its friends.

The first sections will focus on drawing out these connections. We will then get into the details on the derivations for common methods. 

This video is an overview of some of the concepts we discuss. Don't worry about the mathematical details in the video. For a given model, we will go into greater depth in the future. Focus on the general concepts and process. The notes to follow in sections 5.1 and 5.2 elaborate on the concepts in the video.

```{r, echo=FALSE, warning=FALSE, message=FALSE}
library("vembedr")

embed_url("https://www.youtube.com/watch?v=jHCsPLDcWTM")
```

I also encourage you to watch this video from StatQuest to get an initial understanding of likelihood and what it means to "choose the maximum likelihood" using a visual example.

  - StatQuest [video](https://www.youtube.com/watch?v=XepXtl9YKwc)
  
These concepts are also addressed in: King, Gary. 1998. Unifying political methodology: The likelihood theory of statistical inference. University of Michigan Press. Note: Available as an electronic resource through the Rutgers library. Chapters 1, 2, 3, 4.6-4.8. (Available online through Rutgers University)


## What is likelihood?

Just like the derivation of the OLS coefficient estimators $\hat \beta$ for the $\beta$ parameters started with a goal (minimizing least squared errors) in describing the relationship between variables, with likelihood we also start with a goal.

The "***likelihood***" is going to ask the question: ***What values of the unknown parameters make the data we see least surprising?***

When we get into likelihood, we will be drawing more directly on concepts within probability. We start by making a choice about what type of data generating process best describes our outcome data. Eventually, our likelihood function represents the "probability density of the data given the parameters and predictors." (Definition taken from Gelman et al. 2020, pg. 105).

  - In MLE, we are going to choose parameter estimates $\widehat{\theta}$ for $\theta$ that maximize the likelihood that our data came from the particular distribution.

Already, we are placing a lot of emphasis on the nature of our outcome data. The nature of our likelihood will change depending on if the data are dichotomous (e.g, similar to a set of coin flips that could be head or tails) or a count (e.g., similar to the number of events expected to occur over a certain interval) or more of a continuous numeric distribution with (e.g., where the probabilities of certain levels can be visualized similar to a bell curve). Each of these sets of data are generated through a different process, which is described by a particular probability function.

*Example*

This introduction is based on Ben Lambert's video. I highly recommend watching this 8-9 minute [video](https://www.youtube.com/watch?v=I_dhPETvll8). Below we highlight a few of the key concepts and definitions. 

Take the UK population of 70 million. We have a sample of this, and in our sample some observations are male and some female. How can we use what we have, a sample, to estimate the probability that an individual is male?^[In the future, we may want to know the probability of turning out to vote, or of going to war, or voting "yes" on a particular policy question, etc.]

  - First, we can make a judgment about the data generating process. We can suppose there is some probability distribution function that determines the probability is a male or female. 
      + Let's call this $f(y_i | p)$ where $y_i = 1$ if male, 0 if female. 
      + We will say $p$ is the probability an individual is male. $p^{y_i}(1 - p)^{1-y_i}$
 
 - We are going to treat this like a toss of a coin, which has a Bernouilli distribution (every probability distribution we are dealing with is going to have an associated formula. You don't need to memorize these. You can look them up on the internet when needed.) So, $f()$ tells us the probability we would have gotten the observation if we think of our observation as toss of coin. This is the likelihood for a single observation.
 
  - For example, we can now plug this into our Bernoulli function for the two possible cases of $y_i$.
      + $f(1|p) = p^1(1-p)^{1-1} = p$  probability an individual is male
      + $f(0 |p) p ^0(1-p)^{1-0} = 1-p$ probability individual is female

  - Now we want an estimate using our entire sample of observations, not just a single $i$. What if we have $n$ observations? $f(y_1, y_2, ... y_n | p)$. We can write the joint probability as all individual probabilities multiplied together. 
      + $L = P(Y_1 = y_1, Y_2=y_2, ..., Y_n = y_n)= \prod_{i=1}^n p^y_i(1 - p)^{1-y_i}$
      + This answers what is the probability that $Y_1$ took on the particular value $y_1$
      + Ok, now we have the statement $L = P(Y_1 = y_1, Y_2=y_2, ..., Y_n = y_n)$. This joint probability is the likelihood. 
  - Generally, we don't know $p$. We are trying to estimate it.***What we want to do is choose the $\hat p$ to maximize the likelihood that we would have gotten this set of observations given that $Y_i$ has a probability distribution as specified.***
      + We have used a buzz word: "maximize." Just as in OLS, that should be our signal that a derivative should be taken so that we can find the quantities that represent the maximum.
      + We differentiate L with respect to p, set it to 0, to give us $\hat{p}$.
  - Our issue (or at least one of our issues) is that products are tough to differentiate. A chain rule disaster. Instead, we use a trick of taking the log of the likelihood: log $\prod ()$.^[Why does this work? It has to do with the shape of the log (always increasing). Details are beyond the scope.] Benefit: it turns it into a sum, much easier. $\log ab = \log a + \log b$. So we will actually differentiate the $\log$ of the likelihood. Yes, this is why we had logs as part of Section 3. 


### Summarizing Steps for Maximum Likelihood

Initial Setup

  1. What is the data generating process? This means think about the structure of the dependent variable. Is it continuous, is it a count, is it binary, is it ordered?  Based on this, describe the probability distribution for $Y_i$.
  2. Define the likelihood for a single observation
  3. Define the likelihood for all observations
  4. Find the log-likelihood

Then, the derivation begins! Yes, we've only just [begun](https://www.youtube.com/watch?v=uaqoQr-aCtQ), but that first step of deciding the data generating process is huge.

**Example: Count Data**

Let's say we are trying to understand the relationship between an independent variable and the number of news articles reported on a topic. This is a count of data. It goes from 0 to some positive number, never extending below 0. A distribution that is a good fit for this is the Poisson. We start by specifying this as our data generating process and looking up the Poisson probability density function, which has the parameter $\lambda$.

  1. Data Generating Process and probability density function.
  
\begin{align*}
&Y_i \stackrel{\rm i.i.d.}{\sim} Pois(\lambda)\Rightarrow\\
&\Pr(Y=Y_i|\lambda)=\lambda \frac{exp(-\lambda) \lambda^{Y_i}}{Y_i!}
\end{align*}

Note: we assume our observations are iid (independently and identically distributed (For [definition](http://www.statisticshowto.com/iid-statistics/}).) This assumption can be relaxed.

  2. What is the likelihood for a single observation?
  
\begin{align*}
\mathcal L(\lambda|Y_i)=\Pr(Y=Y_i|\lambda)
\end{align*}

  3.  What is the likelihood for all observations?
  
\begin{align*}
\mathcal L(\lambda|Y)&=\mathcal L(\lambda|Y_1)\times\mathcal  L(\lambda|Y_2)\times \ldots \times \mathcal L(\lambda|Y_{N})\\
\mathcal L(\lambda|Y)&=\prod_{i=1}^N\mathcal L(\lambda|Y_i)\\
\end{align*}

  4.  Easier to work with log-likelihood
  
\begin{align*}
\ell(\lambda|Y)&=\sum_{i=1}^N\mathcal \log(\mathcal L(\lambda|Y_i))\\
\end{align*}

Given observed data $Y$, what is the likelihood it was generated from $\lambda$? We will be choosing estimates of the parameters that maximize the likelihood we would have seen these data. Generally, we will also consider parameters like $\lambda$ to be functions of our covariates-- the things we think help explain our otucome.

For additonal practice, try to write down the likelihood of a single observation, the likelihood for all observations, and the log likelihood for an outcome we believe is normally distributed. We have $Y_i \sim N(\mu, \sigma^2)$. Our PDF is:

\begin{align*}
f(Y_i | \theta) &=  \frac{1}{\sigma\sqrt{2\pi}}e^{\frac{-(Y_i-\mu)^2}{2\sigma^2}}
\end{align*}

You can take it from here.

## Generalized Linear Models

Before we get into the details of deriving the estimators, we are going to discuss another connection between linear models and the types of models we will work with when we are using common maximum likelihood estimators.

Recall our linear model: $y_i =  \beta_o + \beta_1x_{i1} + ... \beta_kx_{ik} + \epsilon$

  - $Y$ is modelled by a linear function of explanatory variables $X$
  - $\hat \beta$ is our estimate of how much $X$ influences $Y$ (the slope of the line)
  - On average, a one-unit change in $X_{ik}$ is associated with a $\hat \beta_{k}$ change in $Y_i$
  - Slope/rate of change is linear, does not depend on where you are in $X$. Every one-unit change has the same expected increase or decrease

Sometimes we are dealing with outcome data that are restricted or "limited" in some way such that this standard linear predictor will no longer make sense. If we keep changing $X$ we may eventually generate estimates of $\hat y$ that extend above or below the plausible range of values for our actual observed outcomes.

The generalized linear model framework helps address this problem by adding two components: a nonlinear transformation and a probability model. This allows us to make predictions of our outcomes that retain the desired bounded qualities of our observed data. Generalized linear models include linear regression as a special case (a case where no nonlinear transformation is required), but as its name suggests, is much more general and can be applied to many different outcome structures.

### GLM Model.

In a GLM, we still have a "linear predictor": $\eta_i = \beta_o + \beta_1x_{i1} + ... + \beta_kx_{ik}$

  - But our $Y_i$ might be restricted in some way (e.g., might be binary).
  - So, now we require a "link" function which tells us how $Y$ depends on the linear predictor. This is the key to making sure our linear predictor, when transformed, will map into sensible units of Y.
  
Our $Y_i$ will also now be expressed in terms of a probability model. For example, when we have binary outcome data, such as $y_i =$ 1 or 0 for someone turning out to vote or not, we may try to estimate the probability that someone turns out to vote given certain explanatory variables. We can write this as $Pr(Y_i = 1 | x_i$).

In a GLM, we need a way to transform our linear predictor such that as we shift in values of $X\hat \beta$, we stay within plausible probability ranges. 

  - To do so we use a "link" function that is used to model the data.
      + For example, in logistic regression, our link function will be the "logit":
      
      \begin{align*}
Pr(Y_i = 1 | x_i) &= \pi_i\\
\eta_i &= \text{logit}(\pi_i) = \log \frac{\pi_i}{1-\pi_i} &= \beta_o + \beta_1x_{i1} + ... + \beta_kx_{ik}
\end{align*}

  - One practical implication of this is that when we generate our coefficient estimates $\hat \beta$, these will no longer be in units if $y_i$ or even in units of probability. Instead, they will be in units as specified by the link function. In logistic regression, this means they will be in "logits." 
    + For every one-unit change in $x_k$, we get a $\hat \beta_k$ change in **logits** of $y$
    
  - However, the nice thing is that because we know the link function, with a little bit of work, we can transform our estimates back into the units of $y_i$ that we care about.

\begin{align*}
Pr(Y_i = 1 | x_i) &= \pi_i = g^{-1}(\eta_i) \\
&= \text{logit}^{-1}(\pi_i) \\
&= \frac{exp^{x_i'\beta}}{1 + exp^{x_i'\beta}}
\end{align*}
  
  
### Linking likelihood and the GLM

Let's use $\theta$ to represent the parameters of the pdf/pmf that we have deemed appropriate for our outcome data. As discussed before, we can write the likelihood for an observation as a probability statement. 

  - $\mathcal L (\theta | Y_i) = \Pr(Y=Y_i | \theta)$

In social science, instead of thinking of these parameters as just constants (e.g., $p$ or $\mu$), we generally believe that they vary according to our explanatory variables in $X$. We think $Y_i$ is distributed according to a particular probability function and that the parameters that shape that distribution are a function of the covariates.

  - $Y_i \sim f(y_i | \theta_i)$ and $\theta_i = g(X_i, \beta)$

Each type of model we come across--guided by the structure of the dependent variable-- is just going to have different formulas for each of these components. 

**Examples**

|Model | PDF | $\theta_i$ ; Link$^{-1}$ | $\eta_i$|  
|:-------|-------|---------|--------|------:|
|Linear  | $Y_i \sim \mathcal{N}(\mu_i,\sigma^2)$ | $\mu_i = X_i^\prime\beta$ | $\mu_i$|
|Logit   | $Y_i \sim \rm{Bernoulli}(\pi_i)$ | $\pi_i=\frac{\exp(X_i^\prime\beta)}{(1+\exp(X_i^\prime\beta))}$ | logit$(\pi_i)$|
|Probit  | $Y_i \sim \rm{Bernoulli}(\pi_i)$ | $\pi_i = \Phi(X_i^\prime\beta)$ | $\Phi^{-1}(\pi_i)$|

These generalized linear models are then fit through maximum likelihood estimation, through an approach discussde in the next section. Note: not all ML estimators can be written as generalized linear models, though many we use in political science are indeed GLMs. To be a GLM, the distribution we specify for the data generating process has to be a part of the exponential family of probability distributions (fortunately the gaussian normal, poisson, bernouilli, binomial, gamma, and negative binomial are), and after that, we need the linear predictor and link function.

### GLM in R

The way generalized linear models work in R is very similar to lm.

Below is a simple example where we will specify a linear model in `lm()` and `glm()` to compare.

```{r}
## Load Data
florida <- read.csv("https://raw.githubusercontent.com/ktmccabe/teachingdata/main/florida.csv")

fit.lm <- lm(Buchanan00 ~ Perot96, data=florida)
fit.glm <- glm(Buchanan00 ~ Perot96, data=florida, 
               family=gaussian(link = "identity"))
```

For the glm, we just need to tell R the family of distributions we are using and the appropriate link function. In this example, we are going to use the normal gaussian distribution to describe the data generating process for `Buchanan00`. This is appropriate for nice numeric continuous data, even if it isn't perfectly normal. The normal model has a link function, but it is the special case where the link function is just the identity. There is no nonlinear transformation that takes place. Therefore, we can still interpret the $\hat \beta$ results in units of $Y$ (votes in this case).

In this special case, the $\hat \beta$ estimates from `lm()` and `glm()` will be the same.

```{r}
coef(fit.lm)
coef(fit.glm)
```

There are some differences in the mechanics of how we get to the results in each case, but we will explore those more in the next section. I.e., these coefficients do not come out of thin air. Just like in OLS, we have to work for them.

