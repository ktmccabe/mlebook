[
["index.html", "MLE for Political Science Section 1 Course Overview", " MLE for Political Science Instructor: Katie McCabe Section 1 Course Overview This document will include important links and course notes for 16:790:677:01: Maximum Likelihood Estimation. This webpage will be updated throughout the semester with new content. This initial content in Sections 2 and 3 is optional, but encouraged, and includes tutorials and resources for basics in R and mathematical concepts used in the course. Material introduced in the course will assume some familiarity with these concepts. I recommend you go through on your own leading up to and during the first week of the course. You can then always return to it throughout the course and beyond. I always have to return to it because I don’t often keep the special rules of logarithms and derivatives in my working memory. Sprinkled throughout this document are links to additional resources that might provide more in-depth explanations of a given topic. This is a new and living document. If you spot errors or have questions or suggestions, please email me at k.mccabe@rutgers.edu. "],
["rover.html", "Section 2 R Overview", " Section 2 R Overview This course will primarily use R for analysis, though we will briefly discuss a few areas where Stata may be more efficient. Learning to program in R is not a primary goal of this course, but in proceeding through the course, you will gain and/or get practice with a lot of R skills. For those brand new to R, I strongly recommend you complete the following tutorials prior to or at the beginning of the course. Goal By the end of the first week of the course, you will want to have R and RStudio installed on your computer (both free) and feel comfortable using R as a calculator and loading datasets into R. R and RStudio Installation This video from Christopher Bail explains the R and RStudio installation process. This involves Going to cran, select the link that matches your operating system, and then follow the installation instructions, and Visiting RStudio and follow the download and installation instructions. R is the statistical software and programming language used for analysis. RStudio provides a convenient user interface for running R code. You do not need RStudio to use R, but it is free and can make your life easier! After installing R and RStudio, you can also follow along with Christopher Bail’s R Basics and Data Wrangling videos to learn the basic functionality of R. Supplemental Resources To supplement the above resources, I would recommend playing around with one of the following: An additional great resource is Kosuke Imai’s book Quantitative Social Science. The first chapter provides a written overview of installing R and the basic functions of R and R Studio, including loading data and packages into R. Data for the book is available at the bottom of this page. Alternate coding in tidyverse for the book is available here. If you were having difficulties following Chris Bail or Kosuke Imai’s instructions for installation, you can try following the first couple of Rutgers Data Librarian Ryan Womack’s videos, which similarly start from the point of installation. They are here. He goes at a slow pace and codes along in the videos. He also has a number of videos on more advanced data analysis topics. R for Data Science is another great resource and focuses on “tidyverse” code in R, which can be particularly helpful in data wrangling and visualization. Note: Much of the code used in the course will rely on “base R” functions (functions that already exist in R). People have also developed tidyverse packages that can be easily installed in R, which supplements base R tools with alternative functions and a syntax based on a particular design philosophy, grammar, and data structure that they find preferable to base R. Using base R vs. tidyverse is often just a matter of personal taste. Either is fine to use in this course, and you will get exposure to code that relies on both. This is a lot of information to digest all at once. Don’t worry. No one remembers everything. Plan on going back to these resources often throughout the course and beyond. We will have office hours the first week of the course to help troubleshoot issues. "],
["first-time-with-r-and-rstudio.html", "2.1 First Time with R and RStudio", " 2.1 First Time with R and RStudio This next section provides a few notes on using R and RStudio now that you have installed it. This is mostly repetitive of the other resources. This includes only the bare essential information for opening an R script and digging into using R as a calculator, which we will do in chapter 3. In this section, we cover the following materials: Using R as a calculator and assigning objects using &lt;- Setting your working directory and the setwd() function. Creating and saving an R script 2.1.1 Open RStudio RStudio is an open-source and free program that greatly facilitates the use of R, especially for users new to programming. Once you have downloaded and installed R and RStudio, to work in R, all you need to do now is open RStudio (it will open R). It should look like this, though your version number may be different: (Image from Kosuke Imai’s Quantitative Social Science Figure 1.1) Note: If you only have three windows (e.g., no upper-left window), you may need to open an R script. To do this, in RStudio, click on File, New, and then R script. This will open a blank document for text editing in the upper left of the RStudio window. We will return to this window in a moment. 2.1.2 Using R as a Calculator The bottom left window in your RStudio is the Console. You can type in this window to use R as a calculator or to try out commands. It will show the raw output of any commands you type. For example, we can try to use R as a calculator. Type the following in the Console (the bottom left window) and hit “enter” or “return” on your keyboard: 5 + 3 ## [1] 8 5 - 3 ## [1] 2 5^2 ## [1] 25 5 * 3 ## [1] 15 5/3 ## [1] 1.666667 (5 + 3) * 2 ## [1] 16 In the other RStudio windows, the upper right will show a history of commands that you have sent from the text editor to the R console, along with other items. The lower right will show graphs, help documents and other features. These will be useful later in the course. 2.1.3 Working in an R Script Earlier, I asked you to open an R script in the upper left window by doing File, then New File, then R Script. Let’s go back to working in that window. Set your working directory setwd() (Almost) every time you work in RStudio, the first thing you will do is set your working directory. This is a designated folder in your computer where you will save your R scripts and datasets. There are many ways to do this. An easy way is to go to Session \\(\\rightarrow\\) Set Working Directory \\(\\rightarrow\\) Choose Directory. I suggest choosing a folder in your computer that you can easily find and that you will routinely use for this class. Go ahead and create/select it. Note: when you selected your directory, code came out in the bottom left Console window. This is the setwd() command which can also be used directly to set your working directory in the future. If you aren’t sure where your directory has been set, you can also type getwd() in your Console. Try it now ## Example of where my directory was getwd() If I want to change the working directory, I can go to the top toolbar of my computer and use Session \\(\\rightarrow\\) Set Working Directory \\(\\rightarrow\\) Choose Directory or just type my file pathway using the setwd() below: ## Example of setting the working directory using setwd(). ## Your computer will have your own file path. setwd(&quot;/Users/ktmccabe/Dropbox/Rutgers Teaching/&quot;) Saving the R Script Let’s now save our R script to our working directory and give it an informative name. To do so, go to File, then Save As, make sure you are in the same folder on your computer as the folder you chose for your working directory. Give the file an informative name, such as: “McCabeWeek1.R”. Note: all of your R scripts will have the .R extension. 2.1.4 Preparing your R script Now that we have saved our R script, let’s work inside of it. Remember, we are in the top-left RStudio window now. Just like the beginning of a paper, you will want to title your R script. In R, any line that you start with a # will not be treated as a programming command. You can use this to your advantage to write titles/comments. Below is a screenshot example of a template R script. You can specify your working directory at the top, too. Add your own filepath inside setwd() Then you can start answering problems in the rest of the script. Think of the R script as where you write the final draft of your paper. In the Console (the bottom-left window), you can mess around and try different things, like you might when you are taking notes or outlining an essay. Then, write the final programming steps that lead you to your answer in the R script. For example, if I wanted to add 5 + 3, I might try different ways of typing it in the Console, and then when I found out 5 + 3 is the right approach, I would type that into my script. 2.1.5 Executing Commands in your R script The last thing we will note in this initial handout is how to execute commands in your R script. To run / execute a command in your R script (the upper left window), you can Highlight the code you want to run, and then hold down “command + return” on a Mac or “control + enter” on Windows Place your cursor at the end of the line of code (far right), and hit “command + return” on a Mac or “control + return” on Windows, or Do 1 or 2, but instead of using the keyboard to execute the commands, click “Run” in the top right corner of the upper-left window. Try it: Type 5 + 3 in the R script. Then, try to execute 5 + 3. It should look something like this: After you executed the code, you should see it pop out in your Console: 5 + 3 ## [1] 8 Note: The symbol # also allows for annotation behind commands or on a separate line. Everything that follows # will be ignored by R. You can annotate your own code so that you and others can understand what each part of the code is designed to do. ## Example sum53 &lt;- 5 + 3 # example of assigning an addition calculation 2.1.6 Objects Sometimes we will want to store our calculations as “objects” in R. We use &lt;- to assign objects by placing it to the left of what we want to store. For example, let’s store the calculation 5 + 3 as an object named sum53: sum53 &lt;- 5 + 3 After we execute this code, sum53 now stores the calculation. This means, that if we execute a line of code that just hassum53`, it will output 8. Try it: sum53 ## [1] 8 Now we no longer have to type 5 + 3, we can just type sum53. For example, let’s say we wanted to subtract 2 from this calculation. We could do: sum53 - 2 ## [1] 6 Let’s say we wanted to divide two stored calculations: ten &lt;- 5 + 5 two &lt;- 1 + 1 ten / two ## [1] 5 The information stored does not have to be numeric. For example, it can be a word, or what we would call a character string, in which case you need to use quotation marks. mccabe &lt;- &quot;professor for this course&quot; mccabe ## [1] &quot;professor for this course&quot; Note: Object names cannot begin with numbers and no spacing is allowed. Avoid using special characters such as % and $, which have specific meanings in R. Finally, use concise and intuitive object names.} GOOD CODE: practice.calc &lt;- 5 + 3 BAD CODE: meaningless.and.unnecessarily.long.name &lt;- 5 + 3 While these are simple examples, we will use objects all the time for more complicated things to store (e.g., like full datasets!) throughout the course. We can also store an array or “vector” of information using c() somenumbers &lt;- c(3, 6, 8, 9) somenumbers ## [1] 3 6 8 9 Importance of Clean Code Ideally, when you are done with your R script, you should be able to highlight the entire script and execute it without generating any error messages. This means your code is clean. Code with typos in it may generate a red error message in the Console upon execution. This can happen when there are typos or commands are misused. For example, R is case sensitive. Let’s say we assigned our object like before: sum53 &lt;- 5 + 3 However, when we went to execute sum53, we accidentally typed Sum53: Sum53 ## Error in eval(expr, envir, enclos): object &#39;Sum53&#39; not found Only certain types of objects can be used in mathematical calculations. Let’s say we tried to divide mccabe by 2: mccabe / 2 ## Error in mccabe/2: non-numeric argument to binary operator A big part of learning to use R will be learning how to troubleshoot and detect typos in your code that generate error messages. 2.1.7 Practice Below is an exercise that will demonstrate you are able to use R as a calculator and create R scripts. Create an R script saved as ``LastnameSetup1.R\" (use your last name). Within the R script, follow the example from this handout and title the script. Set your working directory, and include the file pathway (within setwd()) at the top of your .R script. Do the calculation 4 + 3 - 2 in R. Store it as an object with an informative name. Do the calculation 5 \\(\\times\\) 4 in R. Store it as an object with an informative name. Add these two calculations together. In R, try to do this by adding together the objects you created, not the underlying raw calculations. "],
["tutorials.html", "2.2 Tutorials", " 2.2 Tutorials Occasionally in this course, there will be some interactive tutorials I’ve created that you can do to practice the concepts and R skills. In order to be able to run the tutorials, you need to run the following in your R script. install.packages(\"devtools\", dependencies=T) After devtools is installed, you shouldn’t have to run that line of code again. However, you will need to run the below line each time there is a new tutorial, as this package will be updated throughout the course. devtools::install_github(\"ktmccabe/interactivepack\", dependencies = T) Our first tutorial is practicing R skills to load and manipulate dataframes. You should be able to complete that after reviewing the Chris Bail video and Kosuke Imai QSS Chapter 1 resource. The tutorial is based on information provided in Imai Chapter 1. To load the tutorial, run the line of code below in your RStudio Console. It should open up a web browser on your local machine with the tutorial. If a browser does not open, you may need to manually copy/paste the numeric url that pops out on the console into a browser window. To close out of a tutorial, you can click the stop sign or hit the “Escape” key in the console. If you encounter an error, you may need to install a package or application that is indicated in the error message. learnr::run_tutorial(\"rintro\", package=\"interactivepack\") This is a new program that I am using in this course for the first time to create tutorials, so feel free to email if you encounter bugs!! "],
["math.html", "Section 3 The MATH", " Section 3 The MATH This section will provide an overview of a selection of mathematical skills that will be useful in the course. It will not go into everything, but at least provides a start. MLE will include a range of concepts and skills from linear algebra, calculus, and probability and statistics. You do not need to be an expert in these to succeed in the course, but there are some fundamentals that will make your life easier. Again, the end goal here is not the math. The end goal is to help your become great social scientists. Some popular methods in social science rely on these concepts. The more you can build an intuition for how, when, where, and why these methods work, the more tools you will have to carry out your research and the more credibility and command you will have over the research you conduct. Think about restaurants you have visited. There is a difference between a server who says, “Well we have a chicken” and a server who can tell you exactly how the chicken was cooked, what ingredients were used in the sauce, and maybe even how the chicken was raised. Both dishes may be delicious, but you may gain more trust and understanding from the second. This will not happen overnight nor by the end of the course, but the goal is to continue to progress in understanding. If you pursue a career in academia, this is only the start of years of continued learning and practice. It is a marathon, not a sprint. Extra Resources These are some additional resources that may help supplement the sections to follow. These provide far more detail than you will need in the course, but because of that, are much more comprehensive than the notes that will be outlined: A linear algebra web series. The notes on vector and matrices here will be brief, so this playlist 3Blue1Brown goes into more detail on specific. topics An alternative way of thinking about vectors and matrices is here which gives a more geometric interpretation, which some people find helpful. Will Moore and David Siegel. A Mathematics Course for Political and Social Research. You can get the book or visit the website, which includes some problem sets and solutions, as well as a video syllabus. "],
["mathematical-operations.html", "3.1 Mathematical Operations", " 3.1 Mathematical Operations In this first section, we will review mathematical operations that you have probably encountered before. In many cases, this will be a refresher on the rules and how to read notation. 3.1.1 Order of Operations Many of you may have learned the phrase, “Please Excuse My Dear Aunt Sally” which stands for Parentheses (and other grouping symbols), followed by Exponents, followed by Multiplication and Division from left to right, followed by Addition and Subtraction from left to right. There will be many equations in our future, and we must remember these rules. Example: \\(((1+2)^3)^2 = (3^3)^2 = 27^2 = 729\\) To get the answer, we focused on respecting the parentheses first, identifying the inner-most expression \\(1 + 2 = 3\\), we then moved out and conducted the exponents to get to \\((3^3)^2 = 27^2\\). Note how this is different from the answer to \\(1 + (2^3)^2 = 1 + 8^2 = 65\\), where the addition is no longer part of the parentheses. 3.1.2 Exponents Here is a cheat sheet of some basic rules for exponents. These can be hard to remember if you haven’t used them in a long time. Think of \\(a\\) in this case as a number, e.g., 4, and \\(b\\), \\(k\\), and \\(l\\), as other numbers. \\(a^0 = 1\\) \\(a^1 = a\\) \\(a^k * a^l = a^{k + l}\\) \\((a^k)^l = a^{kl}\\) \\((\\frac{a}{b})^k = (\\frac{a^k}{b^k})\\) These last two rules can be somewhat tricky. Note that a negative exponent can be re-written as a fraction. Likewise an exponent that is a fraction, the most common of which we will encounter is \\(\\frac{1}{2}\\) can be re-written as a root, in this case the square root (e.g., \\(\\sqrt{a}\\)). \\(a^{-k} = \\frac{1}{a^k}\\) \\(a^{1/2} = \\sqrt{a}\\) 3.1.3 Summations and Products The symbol \\(\\sum\\) can be read “take the sum of” whatever is to the right of the symbol. This is used to make the written computation of a sum much shorter than it might be otherwise. For example, instead of writing the addition operations separately in the example below, we can simplify it with the \\(\\sum\\) symbol. This is especially helpful if you would need to add together 100 or 1000 or more things. We will see these appear a lot in the course, for better or worse, so getting comfortable with the notation will be useful. Usually, there is notation just below and just above the symbol (e.g., \\(\\sum_{i=1}^3\\)). This can be read as \"take the sum of the following from \\(i=1\\) to \\(i=3\\). We perform the operation in the expression, each time changing \\(i\\) to a different number, from 1 to 2 to 3. We then add each expression’s output together. Example: \\(\\sum_{i=1}^3 (i + 1)^2 = (1 + 1)^2 + (2 + 1)^2 + (3+1)^2 = 29\\) We will also encounter the product symbol in this course: \\(\\prod\\). This is similar to the summation symbol, but this time we are multiplying instead of adding. Example: \\(\\prod_{k = 1}^3 k^2 = 1^2 \\times 2^2 \\times 3^2 = 36\\) 3.1.4 Logarithms In this class, we will generally assume that \\(\\log\\) takes the natural base \\(e\\), which is a mathematical constant equal to 2.718…. In other books, the base might be 10 by default. If we have, \\(\\log_{10} x = 2\\), this is like saying 10^2 = 100. With base \\(e\\), we have \\(\\log_e x =2\\), which is \\(e^2 = 7.389\\). We are just going to write \\(\\log_e\\) as \\(\\log\\) but know that the \\(e\\) is there. A key part of maximum likelihood estimation is writing down the log of the likelihood equation, so this is a must-have for later in the course. Here is a cheat sheet of common rules for working with logarithms. \\(\\log x = 8 \\rightarrow e^8 = x\\) \\(e^\\pi = y \\rightarrow \\log y = \\pi\\) \\(\\log (a \\times b) = \\log a + \\log b\\) \\(\\log a^n = n \\log a\\) \\(\\log \\frac{a}{b} = \\log a - \\log b\\) Why logarithms? There are many different reasons why social scientists use logs. Some social phenomena grow exponentially, and logs make it is easier to visualize exponential growth, as is the case in visualizing the growth in COVID cases. See this example. Relatedly, taking the log of a distribution that is skewed, will make it look more normal or symmetrical, which has some nice properties. Sometimes the rules of logarithms are more convenient than non-logarithms. In MLE, we will take particular advantage of this rule: \\(\\log (a \\times b) = \\log a + \\log b\\), which turns a multiplication problem into an addition problem. "],
["mathematical-operations-in-r.html", "3.2 Mathematical Operations in R", " 3.2 Mathematical Operations in R We will use R for this course, and these operations are all available with R code, allowing R to become a calculator for you. Here are some examples applying the tools above. 3.2.1 PEMDAS ((1+2)^3)^2 [1] 729 1 + (2^3)^2 [1] 65 3.2.2 Exponents You can compare the computation below to match with the rules above. Note how the caret ^ symbol is used for exponents, and the asterisk * is used for multiplication. We also have a function sqrt() for taking the square root. ## Let&#39;s say a = 4 for our purposes a &lt;- 4 ## And let&#39;s say k= 3 and l=5, b=2 k &lt;- 3 l &lt;- 5 b &lt;- 2 \\(a^0 = 1\\) \\(a^1 = a\\) a^0 a^1 [1] 1 [1] 4 Note how we use parentheses in R to make it clear that the exponent includes not just k but (k + l) \\(a^k * a^l = a^{k + l}\\) a^k * a^l a^(k + l) [1] 65536 [1] 65536 Note how we use the asterisk to make it clear we want to multiply k*l \\((a^k)^l = a^{kl}\\) (a^k)^l a^(k*l) [1] 1073741824 [1] 1073741824 \\((\\frac{a}{b})^k = (\\frac{a^k}{b^k})\\) (a / b)^k (a ^k)/(b^k) [1] 8 [1] 8 \\(a^{-k} = \\frac{1}{a^k}\\) a^(-k) 1 / (a^k) [1] 0.015625 [1] 0.015625 \\(a^{1/2} = \\sqrt{a}\\) a^(1/2) sqrt(a) [1] 2 [1] 2 3.2.3 Summations Summations and products are a little more nuanced in R, depending on what you want to accomplish. But here is one example. Let’s take a vector (think a list of numbers) that goes from 1 to 4. We will call it ourlist. ourlist &lt;- c(1,2,3,4) ourlist ## An alternative is to write this: ourlist &lt;- 1:4 [1] 1 2 3 4 Now let’s do \\(\\sum_{i = 1}^4 (i + 1)^2 = (1 +1)^2 + (1+2)^2 + (1 + 3)^2 + (1 + 4)^2 = 54\\) In R, when you add a number to a vector, it will add that number to each entry in the vector. Example ourlist + 1 [1] 2 3 4 5 We can use that now to do the inside part of the summation. Note: the exponent works the same way, squaring each element of the inside expression. (ourlist + 1)^2 [1] 4 9 16 25 Now, we will embed this expression inside a function in R called sum standing for summation. It will add together each of the inside components. sum((ourlist + 1)^2) [1] 54 If instead we wanted the product, multiplying each element of the inside together, we could use prod(). We won’t use that function very much in this course. 3.2.4 Logarithms R also has functions related to logarithms, called log() and exp() for the for the natural base \\(e\\). By default, the natural exponential is the base in the log() R function. \\(\\log x = 8 \\rightarrow e^8 = x\\) exp(8) [1] 2980.958 log(2980.958) [1] 8 Note that R also has a number of built-in constants, like pi. \\(e^\\pi = y \\rightarrow \\log y = \\pi\\) exp(pi) [1] 23.14069 log(23.14069) [1] 3.141593 \\(\\log (a \\times b) = \\log a + \\log b\\) log(a * b) log(a) + log(b) [1] 2.079442 [1] 2.079442 Let’s treat \\(n=3\\) in this example and enter 3 directly where we see \\(n\\) below. Alternatively you could store 3 as n, as we did with the other letters above. \\(\\log a^n = n \\log a\\) log(a ^ 3) 3 * log(a) [1] 4.158883 [1] 4.158883 \\(\\log \\frac{a}{b} = \\log a - \\log b\\) log(a/b) log(a) - log(b) [1] 0.6931472 [1] 0.6931472 "],
["derivatives.html", "3.3 Derivatives", " 3.3 Derivatives We will need to take some derivatives in the course. The reason is because a derivative gets us closer to understanding how to minimize and maximize certain functions, where a function is a relationship that maps elements of a set of inputs into a set of outputs, where each input is related to one output. This is useful in social science, with methods such as linear regression and maximum likelihood estimation because it helps us estimate the values that we think will best describe the relationship between our independent variables and a dependent variable. For example, in ordinary least squares (linear regression), we choose coefficients, which describe the relationship between the independent and dependent variables (for every 1 unit change in x, we estimate \\(\\hat \\beta\\) amount of change in y), based on a method that tries to minimize the squared error between our estimated outcomes and the actual outcomes. In MLE, we will have a different quantity, which we will try to maximize. To understand derivatives, we will briefly define limits. Limits A limit describes how a function behaves as it approaches (gets very close to) a certain value \\(\\lim_{x \\rightarrow a} f(x) = L\\) Example: \\(\\lim_{x \\rightarrow 3} x^2 = 9\\) The limit of this function as \\(x\\) approaches three, is 9. Limits will appear in the expression for calculating derivatives. 3.3.1 Derivatives For intuition on a derivative, watch this video from The Math Sorcerer. A derivative is the instantaneous rate at which the function is changing at x: the slope of a function at a particular point. There are different notations for indicating something is a derivative. Below, we use \\(f&#39;(x)\\) because we write our functions as \\(f(x) = x\\). Many times you might see a function equation like \\(y = 3x\\) There, it will be common for the derivative to be written like \\(\\frac{dy}{dx}\\). Let’s break down the definition of a derivative by looking at its similarity to the simple definition of a slope, as the rise over the run: Slope (on average): rise over run: change in \\(f(x)\\) over an interval (\\([c, b]\\) where \\(b-c =h\\)): \\(\\frac{f(b) - f(c)}{b-c}\\) For slope at a specific point \\(x\\) (the derivative of f(x) at x), we just make the interval \\(h\\) very small: \\(f&#39;(x)= \\lim_{h \\rightarrow 0}\\frac{f(a + h) - f(a)}{h}\\) Example \\(f(x) = 2x + 3\\). \\(f&#39;(x) = \\lim_{h \\rightarrow 0}\\frac{2(x + h) + 3 - 2x + 3}{h} = \\lim_{h \\rightarrow 0}\\frac{2x + 2h - 2x}{h} = \\lim_{h \\rightarrow 0}2 = 2\\) This twitter thread by the brilliant teacher and statistician Allison Horst, provides a nice cartoon-based example of the derivative. (Note that sometimes the interval \\(h\\) is written as \\(\\Delta x\\), the change in \\(x\\)). Images by Allison Horst 3.3.2 Critical Points for Minima or Maxima In both OLS and MLE, we reach points where take what are called “first order conditions.” This means we take the derivative with respect to a parameter of interest and then set the derivative = 0 and solve for the parameter to get an expression for our estimator. (E.g., In OLS, we take the derivative of the sum of squared residuals, set it equal to zero, and solve to get an expression for \\(\\hat \\beta\\)). The reason we are interested in when the derivative is zero, is because this is when the instanaeous rate of change is zero, i.e., the slope at a particular point is zero. When does this happen? At a critical point- maximum or minimum. Think about it– at the top of a mountain, there is no more rise (and no decline). You are completing level on the mountaintop. The slope at that point is zero. Let’s take an example. The function \\(f(x) = x^2 + 1\\) has the derivative \\(f&#39;(x) = 2x\\). This is zero when \\(x = 0\\). The question remains: How do we know if it is a maximum or minimum? We need to figure out if our function is concave or convex around this critical value. Convex is a “U” shape, meaning we are at a minimum, while concavity is an upside-down-U, which means we are at a maximum. We do so by taking the second derivative. This just means we take the derivative of the expression we already have for our first derivative. In our case, \\(f&#39;&#39;(x) = 2\\). So what? Well the key thing we are looking for is if this result is positive or negative. Here, it is positive, which means our function is convex at this critical value, and therefore, we are at a minimum. Just look at the function in R if we plot it. ## Let&#39;s define an arbitrary set of values for x x &lt;- -3:3 ## Now let&#39;s map the elements of x into y using our function fx &lt;- x^2 + 1 ## Let&#39;s plot the results plot(x = x, y=fx, xlab = &quot;x&quot;, type = &quot;l&quot;, main = &quot;f(x) = x^2 + 1&quot;) Notice that when x=0, we are indeed at a minimum, just as the positive value of the second derivative would suggest. A different example: \\(f(x) = -2x^2 +1\\). \\(f&#39;(x) = -4x\\) When we set this equal to 0 we find a critical value at \\(x = 0\\). \\(f&#39;&#39;(x) = -4\\). Here, the value is negative, and we know it is concave. Sure enough, let’s plot it, and notice how we can draw a horiztonal line at the maximum, representing that zero slope at the critical point: x &lt;- -3:3 fx &lt;- -2*x^2 + 1 plot(x = x, y = fx, ylab = &quot;f(x)&quot;, xlab = &quot;x&quot;, type = &quot;l&quot;, main = &quot;f(x) = -2x^2 + 1&quot;) abline(h=1, col = &quot;red&quot;, lwd=2) 3.3.3 Common Derivative Rules Below is a cheat sheet of rules for quickly identifying the derivatives of functions. The derivative of a constant is 0. \\(f(x) = a; f&#39;(x) = 0\\) Example: The derivative of 5 is 0. Here is the power rule. \\(f(x) = ax^n; f&#39;(x) = n\\times a \\times x^{n-1}\\) Example: The derivative of \\(x^3 = 3x^{(3-1)} = 3x^2\\) We saw logs in the last section, and, yes, we see logs again here. \\(f(x) = e^{ax}; f&#39;(x) = ae^{ax}\\) \\(f(x) = \\log(x); f&#39;(x) = \\frac{1}{x}\\) A very convenient rule is that a derivative of a sum = sum of the derivatives. \\(f(x) = g(x) + h(x); f&#39;(x) = g&#39;(x) + h&#39;(x)\\) Products can be more of a headache. In this course, we will turn some product expressions into summation expressions to avoid the difficulties of taking derivatives with products. Product Rule: \\(f(x) = g(x)h(x); f&#39;(x) = g&#39;(x)h(x) + h&#39;(x)g(x)\\) The chain rule below looks a bit tricky, but it can be very helpful for simplifying the way you take a derivative. See this video from NancyPi for a helpful explainer, as well as a follow-up for more complex applications here. Chain Rule: \\(f(x) = g(h(x)); f&#39;(x) = g&#39;(h(x))h&#39;(x)\\) Example: What is the derivative of \\(f(x) = \\log 5x\\)? First, we will apply the rule which tells us the derivative of a \\(\\log x\\) is \\(\\frac{1}{x}\\). However, here, we do not just have \\(x\\), we have \\(5x\\). We are in chain rule territory. After we apply the derivative to the log, which is \\(\\frac{1}{5x}\\), we then have to take the derivative of \\(5x\\) and multiply the two expressions together. The derivative of \\(5x\\) is \\(5\\). So, putting this together, our full derivative is f′(x) = 5 ∗ \\(\\frac{1}{5x}\\) = \\(\\frac{1}{x}\\). "],
["vectors-and-matrices.html", "3.4 Vectors and Matrices", " 3.4 Vectors and Matrices Vectors For our purposes, a vector is a list or “array” of numbers. For example, this might be a variable in our data– a list of the ages of all politicians in a country. Addition If we have two vectors and , where \\(\\mathbf{u} \\ = \\ (u_1, u_2, \\dots u_n)\\) and \\(\\mathbf{v} \\ = \\ (v_1, v_2, \\dots v_n)\\), \\(\\mathbf{u} + \\mathbf{v} = (u_1 + v_1, u_2 + v_2, \\dots u_n + v_n)\\) Note: \\(\\mathbf{u}\\) and \\(\\mathbf{v}\\) must be of the same dimensionality - number of elements in each must be the same - for addition. Scalar multiplication If we have a scalar (i.e., a single number) \\(\\lambda\\) and a vector \\(\\mathbf{u}\\) \\(\\lambda \\mathbf{u} = (\\lambda u_1, \\lambda u_2, \\dots \\lambda u_n)\\) We can implement vector addition and scalar multiplication in R. Let’s create a vector \\(\\mathbf{u}\\), a vector \\(\\mathbf{v}\\), and a number lambda. u &lt;- c(33, 44, 22, 11) v &lt;- c(6, 7, 8, 2) lambda &lt;- 3 When you add two vectors in R, it adds each component together. u + v [1] 39 51 30 13 We can multiply each element of a vector, u by lambda: lambda * u [1] 99 132 66 33 Element-wise Multiplication Note: When you multiply two vectors together in R, it will take each element of one vector and multiply it by each element of the other vector. u * v \\(= (u_1 * v_1, u_2 * v_2, \\dots u_n * v_n)\\) u * v [1] 198 308 176 22 3.4.1 Matrix Basics A matrix represents arrays of numbers in a rectangle, with rows and columns. A matrix with \\(m\\) rows and \\(n\\) columns is defined as (\\(m\\) x \\(n\\)). What is the dimensionality of the matrix A below? \\(A = \\begin{pmatrix} a_{11} &amp; a_{12} &amp; a_{13}\\\\ a_{21} &amp; a_{22} &amp; a_{23} \\\\ a_{31} &amp; a_{32} &amp; a_{33} \\\\ a_{41} &amp; a_{42} &amp; a_{43} \\end{pmatrix}\\) In R, we can think of a matrix as a set of vectors. For example, we could combine the vectors u and v we created above into a matrix defined as W. ## cbind() binds together vectors as columns Wcol &lt;- cbind(u, v) Wcol u v [1,] 33 6 [2,] 44 7 [3,] 22 8 [4,] 11 2 ## rbind() binds together vectors as rows Wrow &lt;- rbind(u, v) Wrow [,1] [,2] [,3] [,4] u 33 44 22 11 v 6 7 8 2 There are other ways to create matrices in R, but using cbind and rbind() are common. We can find the dimensions of our matrices using dim() or nrow() and ncol() together. For example: dim(Wcol) [1] 4 2 nrow(Wcol) [1] 4 ncol(Wcol) [1] 2 Note how the dimensions are different from the version created with rbind(): dim(Wrow) [1] 2 4 nrow(Wrow) [1] 2 ncol(Wrow) [1] 4 Extracting specific components The element \\(a_{ij}\\) signifies the element is in the \\(i\\)th row and \\(j\\)th column of matrix A. For example, \\(a_{12}\\) is in the first row and second column. Square matrices have the same number of rows and columns Vectors have just one row or one column (e.g., \\(x_1\\) element of \\(\\mathbf{x}\\) vector) In R, we can use brackets to extract a specific \\(ij\\) element of a matrix or vector. Wcol u v [1,] 33 6 [2,] 44 7 [3,] 22 8 [4,] 11 2 Wcol[2,1] # element in the second row, first column u 44 Wcol[2,] # all elements in the second row u v 44 7 Wcol[, 1] # all elements in the first column [1] 33 44 22 11 For matrices, to extract a particular entry in R, you have a comma between entries because there are both rows and columns. For vectors, you only have one entry, so no comma is needed. u [1] 33 44 22 11 u[2] # second element in the u vector [1] 44 3.4.2 Matrix Operations Matrix Addition To be able to add matrix A and matrix B, they must have the same dimensions. Like vector addition, to add matrices, you add each of the components together. \\(A = \\begin{pmatrix} a_{11} &amp; a_{12} &amp; a_{13}\\\\ a_{21} &amp; a_{22} &amp; a_{23} \\\\ a_{31} &amp; a_{32} &amp; a_{33} \\end{pmatrix}\\) and \\(B = \\begin{pmatrix} b_{11} &amp; b_{12} &amp; b_{13}\\\\ b_{21} &amp; b_{22} &amp; b_{23} \\\\ b_{31} &amp; b_{32} &amp; b_{33} \\end{pmatrix}\\) \\(A + B = \\begin{pmatrix} a_{11} + b_{11} &amp; a_{12} + b_{12} &amp; a_{13} + b_{13}\\\\ a_{21} + b_{21} &amp; a_{22} + b_{22} &amp; a_{23} + b_{23} \\\\ a_{31} + b_{31} &amp; a_{32} + b_{32} &amp; a_{33} + b_{33} \\end{pmatrix}\\) \\(Q = \\begin{pmatrix} 2 &amp; 4 &amp; 1\\\\ 6 &amp; 1 &amp; 5 \\end{pmatrix}\\) \\(+\\) \\(R = \\begin{pmatrix} 9 &amp; 4 &amp; 2\\\\ 11 &amp; 8 &amp; 7 \\end{pmatrix} = Q + R = \\begin{pmatrix} 11 &amp; 8 &amp; 3\\\\ 17 &amp; 9 &amp; 12 \\end{pmatrix}\\) Scalar Multiplication Take a scalar \\(\\nu\\). Just like vectors, we multiply each component of a matrix by the scalar. \\(\\nu Q = \\begin{pmatrix} \\nu q_{11} &amp; \\nu q_{12} &amp; \\dots &amp; \\nu q_{1n}\\\\ \\nu q_{21} &amp; \\nu q_{22} &amp; \\dots &amp; \\nu q_{2n} \\\\ \\vdots &amp; \\vdots &amp; \\ddots &amp; \\vdots \\\\ \\nu q_{m1} &amp; \\nu q_{m2} &amp; \\dots &amp; \\nu q_{mn} \\end{pmatrix}\\) Example: Take \\(c = 2\\) and a matrix A. \\(cA = c *\\begin{pmatrix} 4 &amp; 6 &amp; 1\\\\ 3 &amp; 2 &amp; 8 \\end{pmatrix}\\) = \\(\\begin{pmatrix} 8 &amp; 12 &amp; 2\\\\ 6 &amp; 4 &amp; 16 \\end{pmatrix}\\) Note the Commutativity/Associativity: For scalar \\(c\\): \\(c(AB) = (cA)B = A(cB) = (AB)c\\). Matrix Multiplication A matrix A and B must be conformable to multiply AB. To be comformable, for \\(m_A\\) x \\(n_A\\) matrix A and \\(m_B\\) x \\(n_B\\) matrix B, the “inside” dimensions must be equal: \\(n_A = m_B\\). The resulting AB has the “outside” dimensions: \\(m_A\\) x \\(n_B\\). For each \\(c_{ij}\\) component of \\(C = AB\\), we take the inner product of the \\(i^{th}\\) row of matrix A and the \\(j^{th}\\) column of matrix B. Their product C = AB is the \\(m\\) x \\(n\\) matrix where: \\(c_{ij} =a_{i1}b_{1j} + a_{i2}b_{2j} + \\dots + a_{ik}b_{kj}\\) Example: This \\(2 \\times 3\\) matrix is multiplied by a \\(3 \\times 2\\) matrix, resulting in the \\(2 \\times 2\\) matrix. \\(\\begin{pmatrix} 4 &amp; 6 &amp; 1\\\\ 3 &amp; 2 &amp; 8 \\end{pmatrix}\\) \\(\\times\\) \\(\\begin{pmatrix} 8 &amp; 12 \\\\ 6 &amp; 4 \\\\ 7 &amp; 10 \\end{pmatrix}\\) = \\(\\begin{pmatrix} (4*8 + 6*6 + 1*7) &amp; (4*12 + 6*4 + 1*10) \\\\ (3*8 + 2*6 + 8*7) &amp; (3*12 + 2*4 + 8*10) \\end{pmatrix}\\) For example, the entry in the first row and second column of the new matrix \\(c_{12} = (a_{11} = 4* b_{11} = 12) + (a_{12} = 6*b_{21} = 4) + (a_{13} = 1*b_{31} = 10)\\) We can also do matrix multiplication in R. ## Create a 3 x 2 matrix A A &lt;- cbind(c(3, 4, 6), c(5, 6, 8)) A [,1] [,2] [1,] 3 5 [2,] 4 6 [3,] 6 8 ## Create a 2 x 4 matrix B B &lt;- cbind(c(6,8), c(7, 9), c(3, 6), c(1, 11)) B [,1] [,2] [,3] [,4] [1,] 6 7 3 1 [2,] 8 9 6 11 Note that the multiplication AB is conformable because the number of columns in A matches the number of rows in B: ncol(A) nrow(B) [1] 2 [1] 2 To multiply matrices together in R, we need to add symbols around the standard asterisk for multiplication: A %*% B [,1] [,2] [,3] [,4] [1,] 58 66 39 58 [2,] 72 82 48 70 [3,] 100 114 66 94 That is necessary for multiplying matrices together. It is not necessary for scalar multiplication, where we take a single number (e.g., c = 3) and multiply it with a matrix: c &lt;- 3 c*A [,1] [,2] [1,] 9 15 [2,] 12 18 [3,] 18 24 Note the equivalence of the below expressions, which combine scalar and matrix multiplication: c* (A %*% B) [,1] [,2] [,3] [,4] [1,] 174 198 117 174 [2,] 216 246 144 210 [3,] 300 342 198 282 (c* A) %*% B [,1] [,2] [,3] [,4] [1,] 174 198 117 174 [2,] 216 246 144 210 [3,] 300 342 198 282 A %*% (c * B) [,1] [,2] [,3] [,4] [1,] 174 198 117 174 [2,] 216 246 144 210 [3,] 300 342 198 282 In social science, one matrix of interest is often a rectangular dataset that includes column vectors representing independent variables, as well as another vector that includes your dependent variable. These might have 1000 or more rows and a handful of columns you care about. "],
["additional-matrix-tidbits-that-will-come-up.html", "3.5 Additional Matrix Tidbits that Will Come Up", " 3.5 Additional Matrix Tidbits that Will Come Up Inverse An \\(n\\) x \\(n\\) matrix A is invertible if there exists an \\(n\\) x \\(n\\) inverse matrix \\(A^{-1}\\) such that: \\(AA^{-1} = A^{-1}A = I_n\\) where \\(I_n\\) is the identity matrix (\\(n\\) x \\(n\\)), that takes diagonal elements of 1 and off-diagonal elements of 0. Example: \\(I_n = \\begin{pmatrix} 1_{11} &amp; 0 &amp; \\dots &amp; 0\\\\ 0&amp; 1_{22} &amp; \\dots &amp; 0 \\\\ \\vdots &amp; \\vdots &amp; \\ddots &amp; \\vdots \\\\ 0 &amp; 0 &amp; \\dots &amp; 1_{nn} \\end{pmatrix}\\) Multiplying a matrix by the identity matrix returns in the matrix itself: \\(AI_n = A\\) It’s like the matrix version of multiplying a number by one. Note: A matrix must be square \\(n\\) x \\(n\\) to be invertible. (But not all square matrices are invertible.) A matrix is invertible if and only if its columns are linearly independent. This is important for understanding why you cannot have two perfectly colinear variables in a regression model. We will not do much solving for inverses in this course. However, the inverse will be useful in solving for and simplifying expressions. 3.5.1 Transpose When we transpose a matrix, we flip the \\(i\\) and \\(j\\) components. Example: Take a 4 X 3 matrix A and find the 3 X 4 matrix \\(A^{T}\\). A transpose is usually denoted with as \\(A^{T}\\) or \\(A&#39;\\) \\(A = \\begin{pmatrix} a_{11} &amp; a_{12} &amp; a_{13}\\\\ a_{21} &amp; a_{22} &amp; a_{23} \\\\ a_{31} &amp; a_{32} &amp; a_{33} \\\\ a_{41} &amp; a_{42} &amp; a_{43} \\end{pmatrix}\\) then \\(A^T = \\begin{pmatrix} a&#39;_{11} &amp; a&#39;_{12} &amp; a&#39;_{13} &amp; a&#39;_{14}\\\\ a&#39;_{21} &amp; a&#39;_{22} &amp; a&#39;_{23} &amp; a&#39;_{24} \\\\ a&#39;_{31} &amp; a&#39;_{32} &amp; a&#39;_{33} &amp; a&#39;_{34} \\end{pmatrix}\\) If \\(A = \\begin{pmatrix} 1 &amp; 4 &amp; 2 \\\\ 3 &amp; 1 &amp; 11 \\\\ 5 &amp; 9 &amp; 4 \\\\ 2 &amp; 11&amp; 4 \\end{pmatrix}\\) then \\(A^T = \\begin{pmatrix} 1 &amp; 3 &amp; 5 &amp; 2\\\\ 4 &amp; 1 &amp; 9 &amp; 11 \\\\ 2&amp; 11 &amp; 4 &amp; 4 \\end{pmatrix}\\) Check for yourself: What was in the first row (\\(i=1\\)), second column (\\(j=2\\)) is now in the second row (\\(i=2\\)), first column (\\(j=1\\)). That is \\(a_{12} =4 = a&#39;_{21}\\). We can transpose matrices in R using t(). For example, take our matrix A: A [,1] [,2] [1,] 3 5 [2,] 4 6 [3,] 6 8 t(A) [,1] [,2] [,3] [1,] 3 4 6 [2,] 5 6 8 In R, you can find the inverse of a square matrix with solve() solve(A) Error in solve.default(A): &#39;a&#39; (3 x 2) must be square Note, while A is not square A’A is square: AtA &lt;- t(A) %*% A solve(AtA) [,1] [,2] [1,] 2.232143 -1.553571 [2,] -1.553571 1.089286 3.5.2 Additional Matrix Properties and Rules These are a few additional properties and rules that will be useful to us at various points in the course: Symmetric: Matrix A is symmetric if \\(A = A^T\\) Idempotent: Matrix A is idempotent if \\(A^2 = A\\) Trace: The trace of a matrix is the sum of its diagonal components \\(Tr(A) = a_{11} + a_{22} + \\dots + a_{mn}\\) Example of symmetric matrix: \\(D = \\begin{pmatrix} 1 &amp; 6 &amp; 22 \\\\ 6 &amp; 4 &amp; 7 \\\\ 22 &amp; 7 &amp; 11 \\end{pmatrix}\\) ## Look at the equivalence D &lt;- rbind(c(1,6,22), c(6,4,7), c(22,7,11)) D [,1] [,2] [,3] [1,] 1 6 22 [2,] 6 4 7 [3,] 22 7 11 t(D) [,1] [,2] [,3] [1,] 1 6 22 [2,] 6 4 7 [3,] 22 7 11 What is the trace of this matrix? ## diag() pulls out the diagonal of a matrix sum(diag(D)) [1] 16 3.5.3 Matrix Rules Due to conformability and other considerations, matrix operations are somewhat more restrictive, particularly when it comes to commutativity. Associative \\((A + B) + C = A + (B + C)\\) and \\((AB) C = A(BC)\\) Commutative \\(A + B = B + A\\) Distributive \\(A(B + C) = AB + AC\\) and \\((A + B) C = AC + BC\\) Commutative law for multiplication does not hold– the order of multiplication matters: $ AB BA$ Rules for Inverses and Transposes These rules will be helpful for simplifying expressions. Treat \\(A\\), \\(B\\), and \\(C\\) as matrices below, and \\(s\\) as a scalar. \\((A + B)^T = A^T + B^T\\) \\((s A)^T\\) \\(= s A^T\\) \\((AB)^T = B^T A^T\\) \\((A^T)^T = A\\) and \\(( A^{-1})^{-1} = A\\) \\((A^T)^{-1} = (A^{-1})^T\\) \\((AB)^{-1} = B^{-1} A^{-1}\\) \\((ABCD)^{-1} = D^{-1} C^{-1} B^{-1} A^{-1}\\) 3.5.4 Derivatives with Matrices and Vectors Let’s say we have a \\(p \\times 1\\) “column” vector \\(\\mathbf{x}\\) and another \\(p \\times 1\\) vector \\(\\mathbf{a}\\). Taking the derivative with respect to vector \\(\\mathbf{x}\\). Let’s say we have \\(y = \\mathbf{x}&#39;\\mathbf{a}\\). This process is explained here. Taking the derivative of this is called the gradient. \\(\\frac{\\delta y}{\\delta x} = \\begin{pmatrix}\\frac{\\delta y}{\\delta x_1} \\\\ \\frac{\\delta y}{\\delta x_2} \\\\ \\vdots \\\\ \\frac{dy}{dx_p} \\end{pmatrix}\\) \\(y\\) will have dimensions \\(1 \\times 1\\). \\(y\\) is a scalar. Note: \\(y = a_1x_1 + a_2x_2 + ... + a_px_p\\). From this expression, we can take a set of “partial derivatives”: \\(\\frac{\\delta y}{\\delta x_1} = a_1\\) \\(\\frac{\\delta y}{\\delta x_2} = a_2\\), and so on \\(\\frac{\\delta y}{\\delta x} = \\begin{pmatrix}\\frac{\\delta y}{\\delta x_1} \\\\ \\frac{\\delta y}{\\delta x_2} \\\\ \\vdots \\\\ \\frac{\\delta y}{\\delta x_p} \\end{pmatrix} = \\begin{pmatrix} a_1 \\\\ a_2 \\\\ \\vdots \\\\ a_p \\end{pmatrix}\\) Well, this is just vector \\(\\mathbf{a}\\) Answer: \\(\\frac{\\delta }{\\delta x} \\mathbf{x}^T\\mathbf{a} = \\mathbf{a}\\). We can apply this general rule in other situations. Example 2 Let’s say we want to differentiate the following where vector \\(\\mathbf{y}\\) is \\(n \\times 1\\), \\(X\\) is \\(n \\times k\\), and \\(\\mathbf{b}\\) is \\(k \\times 1\\). Take the derivative with respect to \\(b\\). \\(\\mathbf{y}&#39;\\mathbf{y} - 2\\mathbf{b}&#39;X&#39;\\mathbf{y}\\) Note that the dimensions of the output are \\(1 \\times 1\\), a scalar quantity. Remember the derivative of a sum is the sum of derivatives. This allows us to focus on particular terms. The first term has no \\(\\mathbf{b}\\) in it, so this will contribute 0. The second term is \\(2\\mathbf{b}&#39;X&#39;\\mathbf{y}\\). We can think about this like the previous example \\(\\frac{\\delta }{\\delta b} 2\\mathbf{b}&#39;X&#39;\\mathbf{y} = \\begin{pmatrix} \\frac{\\delta }{\\delta b_1}\\\\ \\frac{\\delta }{\\delta b_2} \\\\ \\vdots \\\\ \\frac{\\delta }{\\delta b_k} \\end{pmatrix}\\) The output is needs to be \\(k \\times 1\\) like \\(\\mathbf{b}\\), which is what \\(2 * X&#39;\\mathbf{y}\\) is. The derivative is \\(-2X&#39;\\mathbf{y}\\) Example 3 Another useful rule when a matrix \\(A\\) is symmetric: \\(\\frac{\\delta}{\\delta x} \\mathbf{x}^TA\\mathbf{x} = (A + A^T)\\mathbf{x} = 2A\\mathbf{x}\\). This has a nice analogue to the derivative we’ve seen before \\(q^2 = 2*q\\). Let’s say we want to take the derivative of \\(\\mathbf{b}&#39;X&#39;X\\mathbf{b}\\) with respect to \\(\\mathbf{b}\\). We can think of \\(X&#39;X\\) as if it is \\(A\\). This gives us \\(2X&#39;X\\mathbf{b}\\) as the result. Why on earth would we care about this? For one, it helps us understand how we get to our estimates for \\(\\hat \\beta\\) in linear regression. When we have multiple variables, we don’t just want the best estimate for one coefficient, but a vector of coefficients. See more here. In MLE, we will find the gradient of the log likelihood function. We will further go into the second derivatives to arrive at what is called the Hessian. More on that later. "],
["practice-problems.html", "3.6 Practice Problems", " 3.6 Practice Problems What is \\(24/3 + 5^2 - (8 -4)\\)? What is \\(\\sum_{i = 1}^5 (i*3)\\)? Take the derivative of \\(f(x) =v(4x^2 + 6)^2\\) with respect to \\(x\\). Take the derivative of \\(f(x) = e^{2x + 3}\\) with respect to \\(x\\). Take the derivative of \\(f(x) = log (x + 3)^2\\) with respect to \\(x\\). Given \\(X\\) is an \\(n\\) x \\(k\\) matrix, \\((X^{T}X)^{-1}X^{T}X\\) can be simplified to? \\(((X^{T}X)^{-1}X^{T})^{T} =\\) ? If \\(\\nu\\) is a constant, how does \\((X^{T}X)^{-1}X^{T} \\nu X(X^{T}X)^{-1}\\) simplify? If a matrix \\(P\\) is idempotent, \\(PP =\\) ? 3.6.1 Practice Problem Solutions What is \\(24/3 + 5^2 - (8 -4)\\)? 24/3 + 5^2 - (8 -4) [1] 29 What is \\(\\sum_{i = 1}^5 (i*3)\\)? By hand: \\(1 \\times 3 + 2 \\times 3 + 3 \\times 3 + 4 \\times 3 + 5 \\times 3\\) ## sol 1 1*3 + 2*3 + 3*3 + 4*3 + 5*3 [1] 45 ## sol 2 i &lt;- 1:5 sum(i*3) [1] 45 Take the derivative of \\(f(x) =v(4x^2 + 6)^2\\) with respect to \\(x\\). We can treat \\(v\\) as a number. \\[\\begin{align*} f&#39;(x) &amp;= 2* v(4x^2 + 6) * 8x\\\\ &amp;= 16vx(4x^2 + 6) \\end{align*}\\] Take the derivative of \\(f(x) = e^{2x + 3}\\) with respect to \\(x\\). \\[\\begin{align*} f&#39;(x) &amp;= 2* e^{2x + 3}\\\\ &amp;= 2e^{2x + 3} \\end{align*}\\] Take the derivative of \\(f(x) = log (x + 3)^2\\) with respect to \\(x\\). Note we can re-write this as \\(2 * log (x + 3)\\). \\[\\begin{align*} f&#39;(x) &amp;= 2 * \\frac{1}{(x + 3)} * 1\\\\ &amp;= \\frac{2}{(x + 3)} \\end{align*}\\] If we didn’t take that simplifying step, we can still solve: \\[\\begin{align*} f&#39;(x) &amp;= \\frac{1}{(x + 3)^2} * 2 * (x + 3) *1\\\\ &amp;= \\frac{2}{(x + 3)} \\end{align*}\\] Given \\(X\\) is an \\(n\\) x \\(k\\) matrix, \\((X^{T}X)^{-1}X^{T}X\\) can be simplified to? \\(I_k\\) the identity matrix \\(((X^{T}X)^{-1}X^{T})^{T} =\\) ? Recall our rule \\((AB)^T = B^TA^T\\) \\(X(X^TX)^{-1}\\) If \\(\\nu\\) is a constant, how does \\((X^{T}X)^{-1}X^{T} \\nu X(X^{T}X)^{-1}\\) simplify? We can pull it out front. \\[\\begin{align*} &amp;= \\nu(X^{T}X)^{-1}X^{T}X(X^{T}X)^{-1} \\\\ &amp;= \\nu (X^{T}X)^{-1} \\end{align*}\\] If a matrix \\(P\\) is idempotent, \\(PP =\\) ? \\(P\\) from section 3.5.2 "],
["ols.html", "Section 4 Review of OLS", " Section 4 Review of OLS This section will provide a review of OLS. OLS is the workhorse of empirical political science. We will learn a lot beyond OLS, but OLS is often “good enough” and sometimes preferable for explaining the relationship between variables. That is to say, MLE will expand your toolkit, but OLS should remain a big part of your toolkit. I recommend that you review the following readings to familiarize yourself with regression. I will make note within this section where particular readings are most relevant. These readings are available on Canvas in the modules- Week 1 section. Wheelan, Charles. 2012. Naked Statistics. W.W. Norton. Chapter 11. This provides an accessible overview of regression and the interpretation of regression results. Gelman, Andrew, and Jennifer Hill. 2006. Data analysis using regression and multilevel/hierarchical models. Cambridge University Press. Chapter 3. This is a slightly more technical overview and includes some R code for running regressions. Building models and breaking models. (Optional) Fox, John. 2015. Applied Regression Analysis and Generalized Linear Models, 2nd Edition. Sage. Chapter 11. This reading describes diagnostic tests to probe whether the model is a good fit of the data. We won’t go into detail about this in this class, but is material classes focused on linear regression will generally cover. Messing, Solomon. “How to break regression.” Lenz, G., &amp; Sahn, A. (2020). “Achieving Statistical Significance with Control Variables and Without Transparency.” Political Analysis, 1-14. doi:10.1017/pan.2020.31. This paper talks about how to build a regression model, and in particular, why adding more and more controls isn’t always a good thing. "],
["introducing-ols-regression.html", "4.1 Introducing OLS Regression", " 4.1 Introducing OLS Regression The regression method describes how one variable depends on one or more other variables. Ordinary Least Squares regression is a linear model with the matrix representation: \\(Y = \\alpha + X\\beta + \\epsilon\\) Given values of variables in \\(X\\), the model predicts the average of an outcome variable \\(Y\\). For example, if \\(Y\\) is a measure of how wealthy a country is, \\(X\\) may contain measures related to the country’s natural resources and/or features of its institutions (things that we think might contribute to how wealthy a country is.) In this equation: \\(Y\\) is the outcome variable (\\(n \\times 1\\)).1 \\(\\alpha\\) is a parameter representing the intercept \\(\\beta\\) is a parameter representing the slope/marginal effect (\\(k \\times 1\\)), and \\(\\epsilon\\) is the error term (\\(n \\times 1\\)). In OLS, we estimate a line of best fit to predict \\(\\hat{Y}\\) values for different values of X: \\(\\hat{Y} = \\hat{\\alpha} + X\\hat{\\beta}\\). When you see a “\\(\\hat{hat}\\)” on top of a letter, that means it is an estimate of a parameter. As we will see in the next section, in multiple regression, sometimes this equation is represented as just \\(\\hat{Y} = X\\hat{\\beta}\\), where this generally means that \\(X\\) is a matrix that includes several variables and \\(\\hat \\beta\\) is a vector that includes several coefficients, including a coefficient representing the intercept \\(\\hat \\alpha\\) We interpret linear regression coefficients as describing how a dependent variable is expected to change when a particular independent variable changes by a certain amount. Specifically: “Associated with each one unit increase in a variable \\(x_1\\), there is a \\(\\hat{\\beta_1}\\) estimated expected average increase in \\(y\\).” If we have more than one explanatory variable (i.e., a multiple regression), we add the phrase “controlling on/ holding constant other observed factors included in the model.” We can think of the interpretation of a coefficient in multiple regression using an analogy to a set of light switches: We ask: How much does the light in the room change when we flip one switch, while holding constant the position of all the other switches? This would be a good place to review the Wheelan chapter and Gelman and Hill 3.1 and 3.2 to reinforce what a regression is and how to interpret regression results. Recall this notation means rows by columns, \\(Y\\) is a vector of length \\(n\\) (the number of observations), and since there is only 1 outcome measure, it is 1 column.↩︎ "],
["diving-deeper-into-ols-matrix-representation.html", "4.2 Diving Deeper into OLS Matrix Representation", " 4.2 Diving Deeper into OLS Matrix Representation In this section, we will review the matrix representation of the OLS regression in more detail and discuss how to derive the estimators for the regression coefficients.2 OLS in Matrix Form: Let \\(X\\) be an \\(n \\times k\\) matrix where we have observations on k independent variables for n observations. Since our model will usually contain a constant term, one of the columns in the X matrix will contain only ones. This column should be treated exactly the same as any other column in the X matrix. Let \\(Y\\) be an \\(n \\times 1\\) vector of observations on the dependent variable. Note: because \\(Y\\) is a vector (a matrix with just one column), sometimes it is written in lowercase notation as \\(\\mathbf y\\). Let \\(\\epsilon\\) be an \\(n \\times 1\\) vector of disturbances or errors. Let \\(\\beta\\) be an \\(k \\times 1\\) vector of unknown population parameters that we want to estimate. \\(\\begin{pmatrix} y_1 \\\\ y_2 \\\\ y_3 \\\\ y_4 \\\\ ... \\\\ y_n \\end{pmatrix}\\) = \\(\\begin{pmatrix} 1 &amp; x_{11} &amp; x_{12} &amp; x_{13} &amp; ... &amp; x_{1k}\\\\ 1 &amp; x_{21} &amp; x_{22} &amp; x_{23} &amp; ... &amp; x_{2k} \\\\ 1 &amp; x_{31} &amp; x_{32} &amp; x_{33} &amp; ... &amp; x_{3k}\\\\ 1 &amp; x_{41} &amp; x_{42} &amp; x_{43} &amp; ... &amp; x_{4k} \\\\ ... &amp; ... &amp; ... &amp; ... &amp; ... &amp; ... \\\\ 1 &amp; x_{n1} &amp; x_{n2} &amp; x_{n3} &amp; ... &amp; x_{nk}\\end{pmatrix}\\) X \\(\\begin{pmatrix} \\alpha \\\\ \\beta_1 \\\\ \\beta_2 \\\\ \\beta_3 \\\\ ... \\\\ \\beta_k \\end{pmatrix}\\) + \\(\\begin{pmatrix} \\epsilon_1 \\\\ \\epsilon_2 \\\\ \\epsilon_3 \\\\ \\epsilon_4 \\\\ ... \\\\ \\epsilon_n \\end{pmatrix}\\) Our estimates are then \\(\\mathbf{ \\hat y} = X\\hat \\beta\\). What are the dimensions of this quantity? Gelman and Hill Section 3.4, pg. 38 provides a nice visual of how this representation maps onto what a typical dataset may look like, where we will try to estimate a set of coefficients that map the relationship between the columns of \\(X\\) and \\(\\mathbf y\\): \\ This is a good place to review Gelman and Hill 3.4 on different notations for representing the regression model. 4.2.1 Estimating the Coefficients Models generally start with some goal. In OLS, our goal is to minimize the sum of squared “residuals.” Here is a video I created to explain why we can represent this as \\(\\mathbf{e&#39;}\\mathbf{e}\\). Note: at the end of the video it should read \\(X\\hat\\beta\\), not \\(\\hat X \\beta\\) What is a residual? It’s the difference between y and our estimate of y: \\(y - \\hat y\\). It represents the error in our prediction– how far off our estimate is of the outcome. We can write this in matrix notation in the following way where \\(\\mathbf e\\) is an \\(n \\times 1\\) vector of residuals– a residual for each observation in the data: \\[\\begin{align*} \\mathbf{e&#39;}\\mathbf{e} &amp;= (Y&#39; - \\hat{\\beta}&#39;X&#39;)(Y - X\\hat{\\beta})\\\\ &amp;=Y&#39;Y - \\hat{\\beta}&#39;X&#39;Y - Y&#39;X\\hat{\\beta} + \\hat{\\beta}&#39;X&#39;X\\hat{\\beta} \\\\ &amp;= Y&#39;Y - 2\\hat{\\beta}&#39;X&#39;Y + \\hat{\\beta}&#39;X&#39;X\\hat{\\beta} \\end{align*}\\] Recall we want a line that minimizes this quantity. We minimize the sum of squared residuals by taking the derivative with respect to \\(\\beta\\). (We want to identify the coefficients that help us achieve the goal of minimizing the squared error.) Because we are now deriving an estimate, we will use the hat over \\(\\beta\\): \\(\\frac{\\delta }{\\delta \\hat \\beta} = -2X&#39;Y + 2X&#39;X\\hat{\\beta}\\) So what is our estimate for \\(\\hat{\\beta}\\)? We take first order conditions \\[\\begin{align*} 0 &amp;=-2X&#39;Y + 2X&#39;X\\hat{\\beta}\\\\ \\hat{\\beta} &amp;= (X&#39;X)^{-1}X&#39;Y \\end{align*}\\] You may wonder how we got to these answers. Don’t worry, you will get your chance to solve this! The important thing to note for now, is that we have an analytic solution to our coefficient estimates. This video from Ben Lambert provides additional intuition for understanding OLS in a matrix form and how it can be useful.↩︎ "],
["ols-regression-in-r.html", "4.3 OLS Regression in R", " 4.3 OLS Regression in R To run a linear regression in R, we use the lm() function. The syntax is lm(y ~ x1, data = mydata) for a regression with y as the name of your dependent variable and there is one explanatory variable x1 where mydata is the name of your data frame. lm(y ~ x1 + x2 , data = mydata) is the syntax for a regression with two explanatory variables x1 and x2, where you would add additional variables for larger multivariate regressions. By default, R will include an intercept term in the regression. 4.3.1 Example: Predicting Current Election Votes from Past Election Votes In the American presidential election in 2000, there was an actual controversy in how ballots were cast in the state of Florida. Social scientists used data comparing the election results from 1996 in the state with 2000 as one way to help detect irregularities in the 2000 vote count. For more information on the background of this example, you can watch this video. We will use the data florida.csv available here: ## Load Data florida &lt;- read.csv(&quot;https://raw.githubusercontent.com/ktmccabe/teachingdata/main/florida.csv&quot;) This data set includes several variables described below, where each row represents the voting information for a particular county in Florida. Name Description county county name Clinton96 Clinton’s votes in 1996 Dole96 Dole’s votes in 1996 Perot96 Perot’s votes in 1996 Bush00 Bush’s votes in 2000 Gore00 Gore’s votes in 2000 Buchanan00 Buchanan’s votes in 2000 In 2000, Buchanan was a third party candidate, similar to Perot in 1996. One might think that counties where Perot received a lot of votes in 1996 should also receive a lot in 2000. That is: with a one-vote increase in Perot’s vote, we might expect an average increase in Buchanan’s 2000 vote. We can translate that language into a regression equation: \\(Buchanan2000 = \\alpha + Perot1996 * \\beta + \\epsilon\\) In R, we run this regression the following way. We will save it as an object fit.1. You can name your regression objects anything you want. fit.1 &lt;- lm(Buchanan00 ~ Perot96, data = florida) summary(model) provides the summary statistics of the model. In particular, the following statistics are important Estimate: point estimate of each coefficient Std. Error: standard error of each estimate t value: indicates the \\(t\\)-statistic of each coefficient under the null hypothesis that it equals zero Pr(&gt;|t|): indicates the two-sided \\(p\\)-value corresponding to this \\(t\\)-statistic where asterisks indicate the level of statistical significance. Multiple R-squared: The coefficient of determination Adjusted R-squared: The coefficient of determination adjusting for the degrees of freedom We will say more to define these quantities in future sections. summary(fit.1) Call: lm(formula = Buchanan00 ~ Perot96, data = florida) Residuals: Min 1Q Median 3Q Max -612.74 -65.96 1.94 32.88 2301.66 Coefficients: Estimate Std. Error t value Pr(&gt;|t|) (Intercept) 1.34575 49.75931 0.027 0.979 Perot96 0.03592 0.00434 8.275 9.47e-12 *** --- Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 Residual standard error: 316.4 on 65 degrees of freedom Multiple R-squared: 0.513, Adjusted R-squared: 0.5055 F-statistic: 68.48 on 1 and 65 DF, p-value: 9.474e-12 R also allows several shortcuts for accessing particular elements of your regression results. Examples: ## Vector of the coefficient estimates only coef(fit.1) (Intercept) Perot96 1.34575212 0.03591504 ## Compute confidence intervals for these coefficients confint(fit.1) 2.5 % 97.5 % (Intercept) -98.03044506 100.72194929 Perot96 0.02724733 0.04458275 ## Table of coefficient results only summary(fit.1)$coefficients Estimate Std. Error t value Pr(&gt;|t|) (Intercept) 1.34575212 49.759306434 0.02704523 9.785065e-01 Perot96 0.03591504 0.004340068 8.27522567 9.473505e-12 ## Extract standard errors only summary(fit.1)$coefficients[,2] (Intercept) Perot96 49.759306434 0.004340068 ## Variance-Covariance matrix vcov(fit.1) (Intercept) Perot96 (Intercept) 2475.9885768 -1.360074e-01 Perot96 -0.1360074 1.883619e-05 ## Note that the square root of the diagonal of this matrix provides the standard errors sqrt(diag(vcov(fit.1))) (Intercept) Perot96 49.759306434 0.004340068 ## Degrees of freedom fit.1$df.residual [1] 65 4.3.2 Plotting Regression Results We often don’t want to hide our data under a bushel basket or in complicated regression models. Instead, we might also want to visualize data in R. The function plot() and the function ggplot() from the package ggplot2 are two terrific and flexible functions for visualizing data. We will use the plot() function to visualize the relationship between Perot and Buchanan votes. The example below provides a few arguments you can use within each of these functions, but they are capable of much more. At the core, plotting functions generally work as coordinate systems. You tell R specifically at which x and y coordinates you want your points to be located (e.g., by providing R with a vector of x values and a vector of y values). Then, each function has its own way of allowing you to add bells and whistles to your figure, such as labels (e.g., main, xlab, ylab), point styles ({}), additional lines and points and text (e.g., abline(), lines(), points(), text()), or x and y scales for the dimensions of your axes (e.g., xlim, ylim). You can create a plot without these additional features, but most of the time, you will add them to make your plots look good! and be informative! We will do a lot of plotting this semester. Note: feel free to use plot() or ggplot() or both. ggplot has similar capabilities as plot but relies on a different “grammar” of graphics. For example, see the subtle differences in the two plots below. ## Plot plot(x = florida$Perot96, # x-values y = florida$Buchanan00, # y-values main = &quot;Perot and Buchanan Votes&quot;, # label for main title ylab = &quot;Buchanan Votes&quot;, # y-axis label xlab = &quot;Perot Votes&quot;, # x-axis label pch = 20) # point type abline(fit.1, col = &quot;red&quot;) # adds a red regression line ## ggplot version library(ggplot2) ggplot(data = florida, # which data frame mapping = aes(x = Perot96, y = Buchanan00)) + # x and y coordinates geom_point() + # tells R we want a scatterplot geom_smooth(method = &quot;lm&quot;, se = FALSE, colour = &quot;red&quot;, data = florida, aes(x=Perot96, y=Buchanan00)) + # adds lm regression line ggtitle(&quot;Perot and Buchanan Votes&quot;) + # main title labs(x = &quot;Perot Votes&quot;, y = &quot;Buchanan Votes&quot;) + # x and y labels theme_bw() # changes theme (e.g., color of background) `geom_smooth()` using formula &#39;y ~ x&#39; ## Note: data = florida, aes(x=Perot96, y=Buchanan00) in the geom_smooth line is not necessary if it is the same mapping at the first line. Required if data are different Tip: you might want to save your plots as .pdf or .png after you create it. You can do this straight from your R code. How you do it varies by function. The files will save to your working directory unless you specify a different file path. The code below is the same as above except it has additional lines for saving the plots: ## Plot pdf(file = &quot;myfirstmleplot.pdf&quot;, width = 7, height = 5) # play around with the dimensions plot(x = florida$Perot96, # x-values y = florida$Buchanan00, # y-values main = &quot;Perot and Buchanan Votes&quot;, # label for main title ylab = &quot;Buchanan Votes&quot;, # y-axis label xlab = &quot;Perot Votes&quot;, # x-axis label pch = 20) # point type abline(fit.1, col = &quot;red&quot;) # adds a red regression line dev.off() # this closes your pdf file ## ggplot version ggplot(data = florida, # which data frame mapping = aes(x = Perot96, y = Buchanan00)) + # x and y coordinates geom_point() + # tells R we want a scatterplot geom_smooth(method = &quot;lm&quot;, , se = FALSE, colour = &quot;red&quot;, data = florida, aes(x=Perot96, y=Buchanan00)) + # adds lm regression line ggtitle(&quot;Perot and Buchanan Votes&quot;) + # main title labs(x = &quot;Perot Votes&quot;, y = &quot;Buchanan Votes&quot;) + # x and y labels theme(plot.title = element_text(hjust = 0.5)) +# centers the title theme_bw() # changes theme (e.g., color of background) ggsave(&quot;myfirstmleggplot.png&quot;, device=&quot;png&quot;, width = 7, height = 5) # saves the last ggplot 4.3.3 Finding Coefficients without lm Let’s put our matrix algebra and R knowledge together. In the previous section, we found that \\(\\hat \\beta = (X&#39;X)^{-1}X&#39;Y\\). If we do that math directly in R, there is no need to use lm() to find those coefficients. To do so, we need \\(X\\) and \\(Y\\). Recall \\(Y\\) is an \\(n \\times 1\\) vector representing the outcome of our model. In this case, \\(Y\\) is Buchanan00. Y &lt;- florida$Buchanan00 Recall, \\(X\\) is a \\(n \\times k\\) matrix representing our independent variables and a column of 1’s for the intercept. Let’s build this matrix using cbind which was introduced in section 2. X &lt;- cbind(1, florida$Perot96) dim(X) [1] 67 2 Great, now we have \\(X\\) and \\(Y\\), so it’s just about a little math. Because \\(Y\\) is a vector, let’s make sure R knows to treat it like an \\(n \\times 1\\) matrix. Y &lt;- cbind(Y) dim(Y) [1] 67 1 Recall the solve() and t() functions take the inverse and transpose of matrices. betahat &lt;- solve(t(X) %*% X) %*% t(X) %*% Y Finally, let’s compare the results from our model using lm() with these results. betahat coef(fit.1) Y [1,] 1.34575212 [2,] 0.03591504 (Intercept) Perot96 1.34575212 0.03591504 We did it! In the problem set, you will get more experience using the analytic solutions to solve for quantities of interest instead of the built-in functions. 4.3.4 Practice Problems Here are a couple of (ungraded) problems to modify the code above and gain additional practice with data wrangling and visualization in R. As you might have noticed in the example, there is a big outlier in the data. We will see how this observation affects the results. Using a linear regression examine the relationship between Perot and Buchanan votes, controlling for Bill Clinton’s 1996 votes. Provide a one sentence summary of the relationship between Perot and Buchanan’s votes. Is the relationship significant at the \\(p &lt; 0.05\\) level? What about the relationship between Clinton and Buchanan votes? What are the confidence intervals for the Perot coefficient results? What is the residual for the estimate for Palm Beach County– PalmBeach in the county variable? Let’s go back to the bivariate case. Subset the data to remove the county PalmBeach. Create a scatterplot of the relationship between Perot votes and Buchanan votes within this subset. This time make the points blue. Add a regression line based on this subset of data. Add a second regression line in a different color based on the initial bivariate regression we ran in the example, where all data were included. Describe the differences in the regression lines. 4.3.5 Code for solutions fit.multiple &lt;- lm(Buchanan00 ~ Perot96 + Clinton96, data = florida) summary(fit.multiple) Call: lm(formula = Buchanan00 ~ Perot96 + Clinton96, data = florida) Residuals: Min 1Q Median 3Q Max -705.06 -49.17 -4.71 27.34 2254.89 Coefficients: Estimate Std. Error t value Pr(&gt;|t|) (Intercept) 14.110353 51.644141 0.273 0.78556 Perot96 0.027394 0.010095 2.714 0.00854 ** Clinton96 0.001283 0.001372 0.935 0.35325 --- Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 Residual standard error: 316.7 on 64 degrees of freedom Multiple R-squared: 0.5196, Adjusted R-squared: 0.5046 F-statistic: 34.61 on 2 and 64 DF, p-value: 6.477e-11 confint(fit.multiple)[2,] 2.5 % 97.5 % 0.007228254 0.047560638 florida$res &lt;- residuals(fit.multiple) florida$res[florida$county == &quot;PalmBeach&quot;] [1] 2254.893 florida.pb &lt;- subset(florida, subset = (county != &quot;PalmBeach&quot;)) fit2 &lt;- lm(Buchanan00 ~ Perot96, data = florida.pb) ggplot(data = florida.pb, # which data frame mapping = aes(x = Perot96, y = Buchanan00)) + # x and y coordinates geom_point(color=&quot;blue&quot;) + # tells R we want a scatterplot geom_smooth(method = &quot;lm&quot;, se = FALSE, colour = &quot;green&quot;, data = florida.pb, aes(x=Perot96, y=Buchanan00)) + # adds lm regression line geom_smooth(method = &quot;lm&quot;, se = FALSE, colour = &quot;red&quot;, data = florida, aes(x=Perot96, y=Buchanan00)) + # adds lm regression line ggtitle(&quot;Perot and Buchanan Votes&quot;) + # main title labs(x = &quot;Perot Votes&quot;, y = &quot;Buchanan Votes&quot;) + # x and y labels theme(plot.title = element_text(hjust = 0.5)) +# centers the title theme_bw() # changes theme (e.g., color of background) `geom_smooth()` using formula &#39;y ~ x&#39; `geom_smooth()` using formula &#39;y ~ x&#39; "],
["week-1-thursday-tutorial.html", "4.4 Week 1 Thursday Tutorial", " 4.4 Week 1 Thursday Tutorial We may be using a tutorial today to get additional practice with linear regression and its assumptions. To load the tutorial you need to have the package devtools installed in your R. Then run the following lines of code. devtools::install_github(&quot;ktmccabe/interactivepack&quot;, dependencies = T) learnr::run_tutorial(&quot;lindep&quot;, package=&quot;interactivepack&quot;) "]
]
