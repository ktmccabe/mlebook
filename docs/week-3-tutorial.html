<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>6.7 Week 3 Tutorial | MLE for Political Science</title>
  <meta name="description" content="6.7 Week 3 Tutorial | MLE for Political Science" />
  <meta name="generator" content="bookdown 0.20 and GitBook 2.6.7" />

  <meta property="og:title" content="6.7 Week 3 Tutorial | MLE for Political Science" />
  <meta property="og:type" content="book" />
  
  
  
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="6.7 Week 3 Tutorial | MLE for Political Science" />
  
  
  

<meta name="author" content="Instructor: Katie McCabe" />



  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="linear-probability-models.html"/>
<link rel="next" href="qoi.html"/>
<script src="libs/header-attrs-2.3/header-attrs.js"></script>
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />









<link href="libs/vembedr-0.1.4/css/vembedr.css" rel="stylesheet" />


<style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<link rel="stylesheet" href="css/style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li class="chapter" data-level="1" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i><b>1</b> Course Overview</a></li>
<li class="chapter" data-level="2" data-path="rover.html"><a href="rover.html"><i class="fa fa-check"></i><b>2</b> R Overview</a>
<ul>
<li class="chapter" data-level="2.1" data-path="first-time-with-r-and-rstudio.html"><a href="first-time-with-r-and-rstudio.html"><i class="fa fa-check"></i><b>2.1</b> First Time with R and RStudio</a>
<ul>
<li class="chapter" data-level="2.1.1" data-path="first-time-with-r-and-rstudio.html"><a href="first-time-with-r-and-rstudio.html#open-rstudio"><i class="fa fa-check"></i><b>2.1.1</b> <strong>Open RStudio</strong></a></li>
<li class="chapter" data-level="2.1.2" data-path="first-time-with-r-and-rstudio.html"><a href="first-time-with-r-and-rstudio.html#using-r-as-a-calculator"><i class="fa fa-check"></i><b>2.1.2</b> <strong>Using R as a Calculator</strong></a></li>
<li class="chapter" data-level="2.1.3" data-path="first-time-with-r-and-rstudio.html"><a href="first-time-with-r-and-rstudio.html#working-in-an-r-script"><i class="fa fa-check"></i><b>2.1.3</b> <strong>Working in an R Script</strong></a></li>
<li class="chapter" data-level="2.1.4" data-path="first-time-with-r-and-rstudio.html"><a href="first-time-with-r-and-rstudio.html#preparing-your-r-script"><i class="fa fa-check"></i><b>2.1.4</b> <strong>Preparing your R script</strong></a></li>
<li class="chapter" data-level="2.1.5" data-path="first-time-with-r-and-rstudio.html"><a href="first-time-with-r-and-rstudio.html#executing-commands-in-your-r-script"><i class="fa fa-check"></i><b>2.1.5</b> <strong>Executing Commands in your R script</strong></a></li>
<li class="chapter" data-level="2.1.6" data-path="first-time-with-r-and-rstudio.html"><a href="first-time-with-r-and-rstudio.html#objects"><i class="fa fa-check"></i><b>2.1.6</b> <strong>Objects</strong></a></li>
<li class="chapter" data-level="2.1.7" data-path="first-time-with-r-and-rstudio.html"><a href="first-time-with-r-and-rstudio.html#practice"><i class="fa fa-check"></i><b>2.1.7</b> <strong>Practice</strong></a></li>
</ul></li>
<li class="chapter" data-level="2.2" data-path="tutorials.html"><a href="tutorials.html"><i class="fa fa-check"></i><b>2.2</b> Tutorials</a></li>
<li class="chapter" data-level="2.3" data-path="data-wrangling.html"><a href="data-wrangling.html"><i class="fa fa-check"></i><b>2.3</b> Data Wrangling</a>
<ul>
<li class="chapter" data-level="2.3.1" data-path="data-wrangling.html"><a href="data-wrangling.html#dealing-with-uninformative-variable-names"><i class="fa fa-check"></i><b>2.3.1</b> Dealing with Uninformative Variable Names</a></li>
<li class="chapter" data-level="2.3.2" data-path="data-wrangling.html"><a href="data-wrangling.html#dealing-with-missing-data"><i class="fa fa-check"></i><b>2.3.2</b> Dealing with Missing Data</a></li>
<li class="chapter" data-level="2.3.3" data-path="data-wrangling.html"><a href="data-wrangling.html#dealing-with-variable-codings-that-arent-quite-right"><i class="fa fa-check"></i><b>2.3.3</b> Dealing with Variable Codings that Aren’t Quite Right</a></li>
<li class="chapter" data-level="2.3.4" data-path="data-wrangling.html"><a href="data-wrangling.html#dealing-with-incomplete-data-merging"><i class="fa fa-check"></i><b>2.3.4</b> Dealing with Incomplete Data (Merging!)</a></li>
<li class="chapter" data-level="2.3.5" data-path="data-wrangling.html"><a href="data-wrangling.html#dealing-with-poorly-shaped-data"><i class="fa fa-check"></i><b>2.3.5</b> Dealing with Poorly Shaped Data</a></li>
<li class="chapter" data-level="2.3.6" data-path="data-wrangling.html"><a href="data-wrangling.html#subsetting-data-by-rows-and-columns"><i class="fa fa-check"></i><b>2.3.6</b> Subsetting data by rows and columns</a></li>
<li class="chapter" data-level="2.3.7" data-path="data-wrangling.html"><a href="data-wrangling.html#reproducing-your-steps"><i class="fa fa-check"></i><b>2.3.7</b> Reproducing your steps</a></li>
</ul></li>
<li class="chapter" data-level="2.4" data-path="tools-for-writing-up-results.html"><a href="tools-for-writing-up-results.html"><i class="fa fa-check"></i><b>2.4</b> Tools for writing up results</a>
<ul>
<li class="chapter" data-level="2.4.1" data-path="tools-for-writing-up-results.html"><a href="tools-for-writing-up-results.html#r-markdown"><i class="fa fa-check"></i><b>2.4.1</b> R Markdown</a></li>
<li class="chapter" data-level="2.4.2" data-path="tools-for-writing-up-results.html"><a href="tools-for-writing-up-results.html#latex"><i class="fa fa-check"></i><b>2.4.2</b> LaTex</a></li>
<li class="chapter" data-level="2.4.3" data-path="tools-for-writing-up-results.html"><a href="tools-for-writing-up-results.html#formatting-and-exporting-r-results"><i class="fa fa-check"></i><b>2.4.3</b> Formatting and Exporting R Results</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="3" data-path="math.html"><a href="math.html"><i class="fa fa-check"></i><b>3</b> The MATH</a>
<ul>
<li class="chapter" data-level="3.1" data-path="mathematical-operations.html"><a href="mathematical-operations.html"><i class="fa fa-check"></i><b>3.1</b> Mathematical Operations</a>
<ul>
<li class="chapter" data-level="3.1.1" data-path="mathematical-operations.html"><a href="mathematical-operations.html#order-of-operations"><i class="fa fa-check"></i><b>3.1.1</b> <strong>Order of Operations</strong></a></li>
<li class="chapter" data-level="3.1.2" data-path="mathematical-operations.html"><a href="mathematical-operations.html#exponents"><i class="fa fa-check"></i><b>3.1.2</b> <strong>Exponents</strong></a></li>
<li class="chapter" data-level="3.1.3" data-path="mathematical-operations.html"><a href="mathematical-operations.html#summations-and-products"><i class="fa fa-check"></i><b>3.1.3</b> <strong>Summations and Products</strong></a></li>
<li class="chapter" data-level="3.1.4" data-path="mathematical-operations.html"><a href="mathematical-operations.html#logarithms"><i class="fa fa-check"></i><b>3.1.4</b> <strong>Logarithms</strong></a></li>
</ul></li>
<li class="chapter" data-level="3.2" data-path="mathematical-operations-in-r.html"><a href="mathematical-operations-in-r.html"><i class="fa fa-check"></i><b>3.2</b> Mathematical Operations in R</a>
<ul>
<li class="chapter" data-level="3.2.1" data-path="mathematical-operations-in-r.html"><a href="mathematical-operations-in-r.html#pemdas"><i class="fa fa-check"></i><b>3.2.1</b> PEMDAS</a></li>
<li class="chapter" data-level="3.2.2" data-path="mathematical-operations-in-r.html"><a href="mathematical-operations-in-r.html#exponents-1"><i class="fa fa-check"></i><b>3.2.2</b> Exponents</a></li>
<li class="chapter" data-level="3.2.3" data-path="mathematical-operations-in-r.html"><a href="mathematical-operations-in-r.html#summations"><i class="fa fa-check"></i><b>3.2.3</b> Summations</a></li>
<li class="chapter" data-level="3.2.4" data-path="mathematical-operations-in-r.html"><a href="mathematical-operations-in-r.html#logarithms-1"><i class="fa fa-check"></i><b>3.2.4</b> Logarithms</a></li>
</ul></li>
<li class="chapter" data-level="3.3" data-path="derivatives.html"><a href="derivatives.html"><i class="fa fa-check"></i><b>3.3</b> Derivatives</a>
<ul>
<li class="chapter" data-level="3.3.1" data-path="derivatives.html"><a href="derivatives.html#derivatives-1"><i class="fa fa-check"></i><b>3.3.1</b> <strong>Derivatives</strong></a></li>
<li class="chapter" data-level="3.3.2" data-path="derivatives.html"><a href="derivatives.html#critical-points-for-minima-or-maxima"><i class="fa fa-check"></i><b>3.3.2</b> <strong>Critical Points for Minima or Maxima</strong></a></li>
<li class="chapter" data-level="3.3.3" data-path="derivatives.html"><a href="derivatives.html#common-derivative-rules"><i class="fa fa-check"></i><b>3.3.3</b> <strong>Common Derivative Rules</strong></a></li>
</ul></li>
<li class="chapter" data-level="3.4" data-path="vectors-and-matrices.html"><a href="vectors-and-matrices.html"><i class="fa fa-check"></i><b>3.4</b> Vectors and Matrices</a>
<ul>
<li class="chapter" data-level="3.4.1" data-path="vectors-and-matrices.html"><a href="vectors-and-matrices.html#matrix-basics"><i class="fa fa-check"></i><b>3.4.1</b> <strong>Matrix Basics</strong></a></li>
<li class="chapter" data-level="3.4.2" data-path="vectors-and-matrices.html"><a href="vectors-and-matrices.html#matrix-operations"><i class="fa fa-check"></i><b>3.4.2</b> Matrix Operations</a></li>
</ul></li>
<li class="chapter" data-level="3.5" data-path="additional-matrix-tidbits-that-will-come-up.html"><a href="additional-matrix-tidbits-that-will-come-up.html"><i class="fa fa-check"></i><b>3.5</b> Additional Matrix Tidbits that Will Come Up</a>
<ul>
<li class="chapter" data-level="3.5.1" data-path="additional-matrix-tidbits-that-will-come-up.html"><a href="additional-matrix-tidbits-that-will-come-up.html#transpose"><i class="fa fa-check"></i><b>3.5.1</b> <strong>Transpose</strong></a></li>
<li class="chapter" data-level="3.5.2" data-path="additional-matrix-tidbits-that-will-come-up.html"><a href="additional-matrix-tidbits-that-will-come-up.html#additional-matrix-properties-and-rules"><i class="fa fa-check"></i><b>3.5.2</b> <strong>Additional Matrix Properties and Rules</strong></a></li>
<li class="chapter" data-level="3.5.3" data-path="additional-matrix-tidbits-that-will-come-up.html"><a href="additional-matrix-tidbits-that-will-come-up.html#matrix-rules"><i class="fa fa-check"></i><b>3.5.3</b> <strong>Matrix Rules</strong></a></li>
<li class="chapter" data-level="3.5.4" data-path="additional-matrix-tidbits-that-will-come-up.html"><a href="additional-matrix-tidbits-that-will-come-up.html#derivatives-with-matrices-and-vectors"><i class="fa fa-check"></i><b>3.5.4</b> <strong>Derivatives with Matrices and Vectors</strong></a></li>
</ul></li>
<li class="chapter" data-level="3.6" data-path="practice-problems.html"><a href="practice-problems.html"><i class="fa fa-check"></i><b>3.6</b> Practice Problems</a>
<ul>
<li class="chapter" data-level="3.6.1" data-path="practice-problems.html"><a href="practice-problems.html#practice-problem-solutions"><i class="fa fa-check"></i><b>3.6.1</b> Practice Problem Solutions</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="4" data-path="ols.html"><a href="ols.html"><i class="fa fa-check"></i><b>4</b> Review of OLS</a>
<ul>
<li class="chapter" data-level="4.1" data-path="introducing-ols-regression.html"><a href="introducing-ols-regression.html"><i class="fa fa-check"></i><b>4.1</b> Introducing OLS Regression</a></li>
<li class="chapter" data-level="4.2" data-path="diving-deeper-into-ols-matrix-representation.html"><a href="diving-deeper-into-ols-matrix-representation.html"><i class="fa fa-check"></i><b>4.2</b> Diving Deeper into OLS Matrix Representation</a>
<ul>
<li class="chapter" data-level="4.2.1" data-path="diving-deeper-into-ols-matrix-representation.html"><a href="diving-deeper-into-ols-matrix-representation.html#estimating-the-coefficients"><i class="fa fa-check"></i><b>4.2.1</b> Estimating the Coefficients</a></li>
</ul></li>
<li class="chapter" data-level="4.3" data-path="ols-regression-in-r.html"><a href="ols-regression-in-r.html"><i class="fa fa-check"></i><b>4.3</b> OLS Regression in R</a>
<ul>
<li class="chapter" data-level="4.3.1" data-path="ols-regression-in-r.html"><a href="ols-regression-in-r.html#example-predicting-current-election-votes-from-past-election-votes"><i class="fa fa-check"></i><b>4.3.1</b> Example: Predicting Current Election Votes from Past Election Votes</a></li>
<li class="chapter" data-level="4.3.2" data-path="ols-regression-in-r.html"><a href="ols-regression-in-r.html#plotting-regression-results"><i class="fa fa-check"></i><b>4.3.2</b> Plotting Regression Results</a></li>
<li class="chapter" data-level="4.3.3" data-path="ols-regression-in-r.html"><a href="ols-regression-in-r.html#finding-coefficients-without-lm"><i class="fa fa-check"></i><b>4.3.3</b> Finding Coefficients without <code>lm</code></a></li>
<li class="chapter" data-level="4.3.4" data-path="ols-regression-in-r.html"><a href="ols-regression-in-r.html#ols-practice-problems"><i class="fa fa-check"></i><b>4.3.4</b> OLS Practice Problems</a></li>
<li class="chapter" data-level="4.3.5" data-path="ols-regression-in-r.html"><a href="ols-regression-in-r.html#code-for-solutions"><i class="fa fa-check"></i><b>4.3.5</b> Code for solutions</a></li>
</ul></li>
<li class="chapter" data-level="4.4" data-path="week-1-thursday-tutorial.html"><a href="week-1-thursday-tutorial.html"><i class="fa fa-check"></i><b>4.4</b> Week 1 Thursday Tutorial</a></li>
<li class="chapter" data-level="4.5" data-path="uncertainty-and-regression.html"><a href="uncertainty-and-regression.html"><i class="fa fa-check"></i><b>4.5</b> Uncertainty and Regression</a>
<ul>
<li class="chapter" data-level="4.5.1" data-path="uncertainty-and-regression.html"><a href="uncertainty-and-regression.html#variance-of-the-coefficients"><i class="fa fa-check"></i><b>4.5.1</b> Variance of the Coefficients</a></li>
<li class="chapter" data-level="4.5.2" data-path="uncertainty-and-regression.html"><a href="uncertainty-and-regression.html#hypothesis-testing"><i class="fa fa-check"></i><b>4.5.2</b> Hypothesis Testing</a></li>
<li class="chapter" data-level="4.5.3" data-path="uncertainty-and-regression.html"><a href="uncertainty-and-regression.html#goodness-of-fit"><i class="fa fa-check"></i><b>4.5.3</b> Goodness of Fit</a></li>
</ul></li>
<li class="chapter" data-level="4.6" data-path="generating-predictions-from-regression-models.html"><a href="generating-predictions-from-regression-models.html"><i class="fa fa-check"></i><b>4.6</b> Generating predictions from regression models</a></li>
<li class="chapter" data-level="4.7" data-path="wrapping-up-ols.html"><a href="wrapping-up-ols.html"><i class="fa fa-check"></i><b>4.7</b> Wrapping up OLS</a>
<ul>
<li class="chapter" data-level="4.7.1" data-path="practice-problems.html"><a href="practice-problems.html#practice-problems"><i class="fa fa-check"></i><b>4.7.1</b> Practice Problems</a></li>
<li class="chapter" data-level="4.7.2" data-path="wrapping-up-ols.html"><a href="wrapping-up-ols.html#practice-problem-code-for-solutions"><i class="fa fa-check"></i><b>4.7.2</b> Practice Problem Code for Solutions</a></li>
</ul></li>
<li class="chapter" data-level="4.8" data-path="week-2-thursday-example.html"><a href="week-2-thursday-example.html"><i class="fa fa-check"></i><b>4.8</b> Week 2 Thursday Example</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="mle.html"><a href="mle.html"><i class="fa fa-check"></i><b>5</b> Introduction to MLE</a>
<ul>
<li class="chapter" data-level="5.1" data-path="what-is-likelihood.html"><a href="what-is-likelihood.html"><i class="fa fa-check"></i><b>5.1</b> What is likelihood?</a>
<ul>
<li class="chapter" data-level="5.1.1" data-path="what-is-likelihood.html"><a href="what-is-likelihood.html#summarizing-steps-for-maximum-likelihood"><i class="fa fa-check"></i><b>5.1.1</b> Summarizing Steps for Maximum Likelihood</a></li>
</ul></li>
<li class="chapter" data-level="5.2" data-path="generalized-linear-models.html"><a href="generalized-linear-models.html"><i class="fa fa-check"></i><b>5.2</b> Generalized Linear Models</a>
<ul>
<li class="chapter" data-level="5.2.1" data-path="generalized-linear-models.html"><a href="generalized-linear-models.html#glm-model."><i class="fa fa-check"></i><b>5.2.1</b> GLM Model.</a></li>
<li class="chapter" data-level="5.2.2" data-path="generalized-linear-models.html"><a href="generalized-linear-models.html#linking-likelihood-and-the-glm"><i class="fa fa-check"></i><b>5.2.2</b> Linking likelihood and the GLM</a></li>
<li class="chapter" data-level="5.2.3" data-path="generalized-linear-models.html"><a href="generalized-linear-models.html#glm-in-r"><i class="fa fa-check"></i><b>5.2.3</b> GLM in R</a></li>
</ul></li>
<li class="chapter" data-level="5.3" data-path="mle-estimation.html"><a href="mle-estimation.html"><i class="fa fa-check"></i><b>5.3</b> MLE Estimation</a>
<ul>
<li class="chapter" data-level="5.3.1" data-path="mle-estimation.html"><a href="mle-estimation.html#deriving-estimators"><i class="fa fa-check"></i><b>5.3.1</b> Deriving Estimators</a></li>
<li class="chapter" data-level="5.3.2" data-path="mle-estimation.html"><a href="mle-estimation.html#score-function"><i class="fa fa-check"></i><b>5.3.2</b> Score function</a></li>
<li class="chapter" data-level="5.3.3" data-path="mle-estimation.html"><a href="mle-estimation.html#hessian-and-information-matrix"><i class="fa fa-check"></i><b>5.3.3</b> Hessian and Information Matrix</a></li>
<li class="chapter" data-level="5.3.4" data-path="mle-estimation.html"><a href="mle-estimation.html#mle-estimation-algorithm"><i class="fa fa-check"></i><b>5.3.4</b> MLE Estimation Algorithm</a></li>
</ul></li>
<li class="chapter" data-level="5.4" data-path="mle-properties.html"><a href="mle-properties.html"><i class="fa fa-check"></i><b>5.4</b> MLE Properties</a>
<ul>
<li class="chapter" data-level="5.4.1" data-path="mle-properties.html"><a href="mle-properties.html#hypothesis-tests"><i class="fa fa-check"></i><b>5.4.1</b> Hypothesis Tests</a></li>
<li class="chapter" data-level="5.4.2" data-path="mle-properties.html"><a href="mle-properties.html#model-output-in-r"><i class="fa fa-check"></i><b>5.4.2</b> Model Output in R</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="6" data-path="binary.html"><a href="binary.html"><i class="fa fa-check"></i><b>6</b> Binary Dependent Variables</a>
<ul>
<li class="chapter" data-level="6.1" data-path="data-generating-process.html"><a href="data-generating-process.html"><i class="fa fa-check"></i><b>6.1</b> Data Generating Process</a>
<ul>
<li class="chapter" data-level="6.1.1" data-path="mle-estimation.html"><a href="mle-estimation.html#mle-estimation"><i class="fa fa-check"></i><b>6.1.1</b> MLE Estimation</a></li>
</ul></li>
<li class="chapter" data-level="6.2" data-path="r-code-for-fitting-logistic-regression.html"><a href="r-code-for-fitting-logistic-regression.html"><i class="fa fa-check"></i><b>6.2</b> R code for fitting logistic regression</a>
<ul>
<li class="chapter" data-level="6.2.1" data-path="r-code-for-fitting-logistic-regression.html"><a href="r-code-for-fitting-logistic-regression.html#writing-down-the-regression-model"><i class="fa fa-check"></i><b>6.2.1</b> Writing down the regression model</a></li>
</ul></li>
<li class="chapter" data-level="6.3" data-path="probit-regression.html"><a href="probit-regression.html"><i class="fa fa-check"></i><b>6.3</b> Probit Regression</a></li>
<li class="chapter" data-level="6.4" data-path="to-logit-or-to-probit.html"><a href="to-logit-or-to-probit.html"><i class="fa fa-check"></i><b>6.4</b> To logit or to probit?</a></li>
<li class="chapter" data-level="6.5" data-path="latent-propensity-representation.html"><a href="latent-propensity-representation.html"><i class="fa fa-check"></i><b>6.5</b> Latent propensity representation</a></li>
<li class="chapter" data-level="6.6" data-path="linear-probability-models.html"><a href="linear-probability-models.html"><i class="fa fa-check"></i><b>6.6</b> Linear Probability Models</a></li>
<li class="chapter" data-level="6.7" data-path="week-3-tutorial.html"><a href="week-3-tutorial.html"><i class="fa fa-check"></i><b>6.7</b> Week 3 Tutorial</a>
<ul>
<li class="chapter" data-level="6.7.1" data-path="week-3-tutorial.html"><a href="week-3-tutorial.html#loading-data-and-fitting-glm"><i class="fa fa-check"></i><b>6.7.1</b> Loading data and fitting glm</a></li>
<li class="chapter" data-level="6.7.2" data-path="week-3-tutorial.html"><a href="week-3-tutorial.html#numeric-optimization"><i class="fa fa-check"></i><b>6.7.2</b> Numeric Optimization</a></li>
<li class="chapter" data-level="6.7.3" data-path="week-3-tutorial.html"><a href="week-3-tutorial.html#predicted-probabilities"><i class="fa fa-check"></i><b>6.7.3</b> Predicted Probabilities</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="7" data-path="qoi.html"><a href="qoi.html"><i class="fa fa-check"></i><b>7</b> Quantities of Interest</a>
<ul>
<li class="chapter" data-level="7.1" data-path="using-the-response-functions-to-generate-quantities-of-interest.html"><a href="using-the-response-functions-to-generate-quantities-of-interest.html"><i class="fa fa-check"></i><b>7.1</b> Using the response functions to generate quantities of interest</a></li>
<li class="chapter" data-level="7.2" data-path="qoi-at-designated-values.html"><a href="qoi-at-designated-values.html"><i class="fa fa-check"></i><b>7.2</b> QOI at Designated Values</a>
<ul>
<li class="chapter" data-level="7.2.1" data-path="qoi-at-designated-values.html"><a href="qoi-at-designated-values.html#marginal-effects"><i class="fa fa-check"></i><b>7.2.1</b> Marginal Effects</a></li>
<li class="chapter" data-level="7.2.2" data-path="qoi-at-designated-values.html"><a href="qoi-at-designated-values.html#marginal-effects-at-the-mean"><i class="fa fa-check"></i><b>7.2.2</b> Marginal effects at the mean</a></li>
<li class="chapter" data-level="7.2.3" data-path="qoi-at-designated-values.html"><a href="qoi-at-designated-values.html#marginal-effects-at-representative-values"><i class="fa fa-check"></i><b>7.2.3</b> Marginal effects at representative values</a></li>
<li class="chapter" data-level="7.2.4" data-path="qoi-at-designated-values.html"><a href="qoi-at-designated-values.html#average-marginal-effects"><i class="fa fa-check"></i><b>7.2.4</b> Average marginal effects</a></li>
<li class="chapter" data-level="7.2.5" data-path="qoi-at-designated-values.html"><a href="qoi-at-designated-values.html#prediction-and-margins-packages."><i class="fa fa-check"></i><b>7.2.5</b> <code>prediction</code> and <code>margins</code> packages.</a></li>
<li class="chapter" data-level="7.2.6" data-path="qoi-at-designated-values.html"><a href="qoi-at-designated-values.html#qoi-practice-problems"><i class="fa fa-check"></i><b>7.2.6</b> QOI Practice Problems</a></li>
</ul></li>
<li class="chapter" data-level="7.3" data-path="uncertainty.html"><a href="uncertainty.html"><i class="fa fa-check"></i><b>7.3</b> Uncertainty</a>
<ul>
<li class="chapter" data-level="7.3.1" data-path="uncertainty.html"><a href="uncertainty.html#bootstrapping"><i class="fa fa-check"></i><b>7.3.1</b> Bootstrapping</a></li>
<li class="chapter" data-level="7.3.2" data-path="uncertainty.html"><a href="uncertainty.html#simulated-confidence-intervals"><i class="fa fa-check"></i><b>7.3.2</b> Simulated Confidence Intervals</a></li>
</ul></li>
<li class="chapter" data-level="7.4" data-path="visualizing-results.html"><a href="visualizing-results.html"><i class="fa fa-check"></i><b>7.4</b> Visualizing Results</a></li>
<li class="chapter" data-level="7.5" data-path="additional-r-shortcuts.html"><a href="additional-r-shortcuts.html"><i class="fa fa-check"></i><b>7.5</b> Additional R shortcuts</a>
<ul>
<li class="chapter" data-level="7.5.1" data-path="additional-r-shortcuts.html"><a href="additional-r-shortcuts.html#prediction"><i class="fa fa-check"></i><b>7.5.1</b> Prediction</a></li>
<li class="chapter" data-level="7.5.2" data-path="additional-r-shortcuts.html"><a href="additional-r-shortcuts.html#margins"><i class="fa fa-check"></i><b>7.5.2</b> Margins</a></li>
<li class="chapter" data-level="7.5.3" data-path="additional-r-shortcuts.html"><a href="additional-r-shortcuts.html#zelig"><i class="fa fa-check"></i><b>7.5.3</b> Zelig</a></li>
<li class="chapter" data-level="7.5.4" data-path="additional-r-shortcuts.html"><a href="additional-r-shortcuts.html#using-expand.grid"><i class="fa fa-check"></i><b>7.5.4</b> Using <code>expand.grid</code></a></li>
</ul></li>
<li class="chapter" data-level="7.6" data-path="week-4-tutorial.html"><a href="week-4-tutorial.html"><i class="fa fa-check"></i><b>7.6</b> Week 4 Tutorial</a></li>
<li class="chapter" data-level="7.7" data-path="putting-everything-together.html"><a href="putting-everything-together.html"><i class="fa fa-check"></i><b>7.7</b> Putting everything together</a></li>
</ul></li>
<li class="chapter" data-level="8" data-path="ordinal.html"><a href="ordinal.html"><i class="fa fa-check"></i><b>8</b> Ordinal Outcomes</a>
<ul>
<li class="chapter" data-level="8.1" data-path="ordinal-outcome-data.html"><a href="ordinal-outcome-data.html"><i class="fa fa-check"></i><b>8.1</b> Ordinal Outcome Data</a>
<ul>
<li class="chapter" data-level="8.1.1" data-path="ordinal-outcome-data.html"><a href="ordinal-outcome-data.html#ordinal-model"><i class="fa fa-check"></i><b>8.1.1</b> Ordinal Model</a></li>
<li class="chapter" data-level="8.1.2" data-path="ordinal-outcome-data.html"><a href="ordinal-outcome-data.html#interpretation"><i class="fa fa-check"></i><b>8.1.2</b> Interpretation</a></li>
</ul></li>
<li class="chapter" data-level="8.2" data-path="likelihood-framework.html"><a href="likelihood-framework.html"><i class="fa fa-check"></i><b>8.2</b> Likelihood Framework</a>
<ul>
<li class="chapter" data-level="8.2.1" data-path="likelihood-framework.html"><a href="likelihood-framework.html#likelihood"><i class="fa fa-check"></i><b>8.2.1</b> Likelihood</a></li>
</ul></li>
<li class="chapter" data-level="8.3" data-path="fitting-ordinal-models-in-r.html"><a href="fitting-ordinal-models-in-r.html"><i class="fa fa-check"></i><b>8.3</b> Fitting Ordinal Models in R</a>
<ul>
<li class="chapter" data-level="8.3.1" data-path="fitting-ordinal-models-in-r.html"><a href="fitting-ordinal-models-in-r.html#quantities-of-interest"><i class="fa fa-check"></i><b>8.3.1</b> Quantities of Interest</a></li>
</ul></li>
<li class="chapter" data-level="8.4" data-path="assumptions.html"><a href="assumptions.html"><i class="fa fa-check"></i><b>8.4</b> Assumptions</a></li>
<li class="chapter" data-level="8.5" data-path="ordinal-practice-problems.html"><a href="ordinal-practice-problems.html"><i class="fa fa-check"></i><b>8.5</b> Ordinal Practice Problems</a>
<ul>
<li class="chapter" data-level="8.5.1" data-path="ordinal-practice-problems.html"><a href="ordinal-practice-problems.html#a-note-on-robust-standard-errors"><i class="fa fa-check"></i><b>8.5.1</b> A note on robust standard errors</a></li>
</ul></li>
<li class="chapter" data-level="8.6" data-path="week-6-tutorial.html"><a href="week-6-tutorial.html"><i class="fa fa-check"></i><b>8.6</b> Week 6 Tutorial</a></li>
</ul></li>
<li class="chapter" data-level="9" data-path="ml.html"><a href="ml.html"><i class="fa fa-check"></i><b>9</b> Multinomial Outcomes</a>
<ul>
<li class="chapter" data-level="9.1" data-path="overview-of-nominal-data.html"><a href="overview-of-nominal-data.html"><i class="fa fa-check"></i><b>9.1</b> Overview of Nominal Data</a>
<ul>
<li class="chapter" data-level="9.1.1" data-path="overview-of-nominal-data.html"><a href="overview-of-nominal-data.html#multinomial-likelihood"><i class="fa fa-check"></i><b>9.1.1</b> Multinomial Likelihood</a></li>
</ul></li>
<li class="chapter" data-level="9.2" data-path="motivating-example.html"><a href="motivating-example.html"><i class="fa fa-check"></i><b>9.2</b> Motivating Example</a>
<ul>
<li class="chapter" data-level="9.2.1" data-path="motivating-example.html"><a href="motivating-example.html#assumption-and-considerations"><i class="fa fa-check"></i><b>9.2.1</b> Assumption and Considerations</a></li>
<li class="chapter" data-level="9.2.2" data-path="motivating-example.html"><a href="motivating-example.html#key-assumption-independence-of-irrelevant-alternatives"><i class="fa fa-check"></i><b>9.2.2</b> Key Assumption: Independence of Irrelevant Alternatives</a></li>
</ul></li>
<li class="chapter" data-level="9.3" data-path="running-multinomial-logit-in-r.html"><a href="running-multinomial-logit-in-r.html"><i class="fa fa-check"></i><b>9.3</b> Running multinomial logit in R</a>
<ul>
<li class="chapter" data-level="9.3.1" data-path="running-multinomial-logit-in-r.html"><a href="running-multinomial-logit-in-r.html#multinomial-quantities-of-interest"><i class="fa fa-check"></i><b>9.3.1</b> Multinomial Quantities of Interest</a></li>
</ul></li>
<li class="chapter" data-level="9.4" data-path="practice-problems-for-multinomial.html"><a href="practice-problems-for-multinomial.html"><i class="fa fa-check"></i><b>9.4</b> Practice Problems for Multinomial</a></li>
<li class="chapter" data-level="9.5" data-path="week-7-tutorial.html"><a href="week-7-tutorial.html"><i class="fa fa-check"></i><b>9.5</b> Week 7 Tutorial</a></li>
</ul></li>
<li class="chapter" data-level="10" data-path="count.html"><a href="count.html"><i class="fa fa-check"></i><b>10</b> Count data</a>
<ul>
<li class="chapter" data-level="10.1" data-path="overview-of-count-data.html"><a href="overview-of-count-data.html"><i class="fa fa-check"></i><b>10.1</b> Overview of Count Data</a></li>
<li class="chapter" data-level="10.2" data-path="poisson-model.html"><a href="poisson-model.html"><i class="fa fa-check"></i><b>10.2</b> Poisson Model</a></li>
<li class="chapter" data-level="10.3" data-path="motivating-example-for-count-data.html"><a href="motivating-example-for-count-data.html"><i class="fa fa-check"></i><b>10.3</b> Motivating Example for Count Data</a>
<ul>
<li class="chapter" data-level="10.3.1" data-path="motivating-example-for-count-data.html"><a href="motivating-example-for-count-data.html#fitting-poisson-in-r"><i class="fa fa-check"></i><b>10.3.1</b> Fitting Poisson in R</a></li>
<li class="chapter" data-level="10.3.2" data-path="motivating-example-for-count-data.html"><a href="motivating-example-for-count-data.html#interpreting-regression-output"><i class="fa fa-check"></i><b>10.3.2</b> Interpreting regression output</a></li>
</ul></li>
<li class="chapter" data-level="10.4" data-path="poisson-quantities-of-interest.html"><a href="poisson-quantities-of-interest.html"><i class="fa fa-check"></i><b>10.4</b> Poisson Quantities of Interest</a>
<ul>
<li class="chapter" data-level="10.4.1" data-path="poisson-quantities-of-interest.html"><a href="poisson-quantities-of-interest.html#expected-counts"><i class="fa fa-check"></i><b>10.4.1</b> Expected Counts</a></li>
<li class="chapter" data-level="10.4.2" data-path="poisson-quantities-of-interest.html"><a href="poisson-quantities-of-interest.html#sidenote-multiplicative-coefficient-interpretation"><i class="fa fa-check"></i><b>10.4.2</b> Sidenote: Multiplicative coefficient interpretation</a></li>
<li class="chapter" data-level="10.4.3" data-path="poisson-quantities-of-interest.html"><a href="poisson-quantities-of-interest.html#incidence-rate-ratios"><i class="fa fa-check"></i><b>10.4.3</b> Incidence Rate Ratios</a></li>
<li class="chapter" data-level="10.4.4" data-path="poisson-quantities-of-interest.html"><a href="poisson-quantities-of-interest.html#where-poisson-is-poisonous"><i class="fa fa-check"></i><b>10.4.4</b> Where Poisson is poisonous:</a></li>
</ul></li>
<li class="chapter" data-level="10.5" data-path="quasipoisson-and-negative-binomial-models.html"><a href="quasipoisson-and-negative-binomial-models.html"><i class="fa fa-check"></i><b>10.5</b> Quasipoisson and Negative Binomial Models</a>
<ul>
<li class="chapter" data-level="10.5.1" data-path="quasipoisson-and-negative-binomial-models.html"><a href="quasipoisson-and-negative-binomial-models.html#negative-binomial-models"><i class="fa fa-check"></i><b>10.5.1</b> Negative Binomial Models</a></li>
</ul></li>
<li class="chapter" data-level="10.6" data-path="count-data-practice-problems.html"><a href="count-data-practice-problems.html"><i class="fa fa-check"></i><b>10.6</b> Count data practice problems</a></li>
<li class="chapter" data-level="10.7" data-path="week-8-tutorial.html"><a href="week-8-tutorial.html"><i class="fa fa-check"></i><b>10.7</b> Week 8 Tutorial</a></li>
<li class="chapter" data-level="10.8" data-path="additional-considerations.html"><a href="additional-considerations.html"><i class="fa fa-check"></i><b>10.8</b> Additional Considerations</a>
<ul>
<li class="chapter" data-level="10.8.1" data-path="additional-considerations.html"><a href="additional-considerations.html#offset"><i class="fa fa-check"></i><b>10.8.1</b> Offset</a></li>
</ul></li>
<li class="chapter" data-level="10.9" data-path="how-to-think-about-zero-counts.html"><a href="how-to-think-about-zero-counts.html"><i class="fa fa-check"></i><b>10.9</b> How to think about Zero Counts</a>
<ul>
<li class="chapter" data-level="10.9.1" data-path="how-to-think-about-zero-counts.html"><a href="how-to-think-about-zero-counts.html#hurdle-models"><i class="fa fa-check"></i><b>10.9.1</b> Hurdle Models</a></li>
<li class="chapter" data-level="10.9.2" data-path="how-to-think-about-zero-counts.html"><a href="how-to-think-about-zero-counts.html#zero-inflated-poissonnegative-binomial"><i class="fa fa-check"></i><b>10.9.2</b> Zero Inflated Poisson/Negative binomial</a></li>
</ul></li>
</ul></li>
</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">MLE for Political Science</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="week-3-tutorial" class="section level2" number="6.7">
<h2><span class="header-section-number">6.7</span> Week 3 Tutorial</h2>
<p>This week’s example, we will replicate a portion of “The Effectiveness of a Racialized Counterstrategy” by Antoine Banks and Heather Hicks, <a href="https://onlinelibrary.wiley.com/doi/epdf/10.1111/ajps.12410">published</a> in the <em>American Journal of Political Science</em> in 2018. The replication data are <a href="https://doi.org/10.7910/DVN/EWRXPU">here</a>.</p>
<p><em>Abstract: Our article examines whether a politician charging a political candidate’s implicit racial campaign appeal as racist is an effective political strategy. According to the racial priming theory, this racialized counterstrategy should deactivate racism, thereby decreasing racially conservative whites’ support for the candidate engaged in race baiting. We propose an alternative theory in which racial liberals, and not racially conservative whites, are persuaded by this strategy. To test our theory, we focused on the 2016 presidential election. We ran an experiment varying the politician (by party and race) calling an implicit racial appeal by Donald Trump racist. We find that charging Trump’s campaign appeal as racist does not persuade racially conservative whites to decrease support for Trump. Rather, it causes racially liberal whites to evaluate Trump more unfavorably. Our results hold up when attentiveness, old-fashioned racism, and partisanship are taken into account. We also reproduce our findings in two replication studies.</em></p>
<p>We will replicate the analysis in Table 1 of the paper, based on an experiment the authors conducted through SSI. They exposed white survey respondents to either a news story about a Trump ad that includes an “implicit racial cue” or conditions that add to this with “explicitly racial” responses from different partisan actors calling out the ad as racist. Drawing on racial priming theory, racially prejudiced whites should be less supportive of Trump after the racial cues are made explicit. The authors test this hypothesis against their own hypothesis that this effect should be more pronounced among “racially liberal” whites.</p>
<p><img src="images/implicit.png" style="width:45.0%" /> <img src="images/explicit.png" style="width:38.0%" /></p>
<p>We are going to focus on a secondary outcome related to whether respondents believed the ad to be about race: “We also suspect that whites should provide a justification for either maintaining or decreasing their support for the candidate alleged to be playing the race card. Our results support these expectations. For example, racial liberals who read about a politician calling Trump’s implicit ad racist are more likely than those in the implicit condition to believe Trump’s ad is about race. On the other hand, pointing out the racial nature of the ad does not cause resentful whites to be any more likely to believe the ad is about race. Racially resentful whites deny that Trump’s subtle racial appeal on crime is racially motivated, which provides them with the evidence they need to maintain their support for his presidency” (320).</p>
<div id="loading-data-and-fitting-glm" class="section level3" number="6.7.1">
<h3><span class="header-section-number">6.7.1</span> Loading data and fitting glm</h3>
<p>Let’s load the data.</p>
<div class="sourceCode" id="cb340"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb340-1"><a href="week-3-tutorial.html#cb340-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(rio)</span>
<span id="cb340-2"><a href="week-3-tutorial.html#cb340-2" aria-hidden="true" tabindex="-1"></a>study <span class="ot">&lt;-</span> <span class="fu">import</span>(<span class="st">&quot;https://github.com/ktmccabe/teachingdata/blob/main/ssistudyrecode.dta?raw=true&quot;</span>)</span></code></pre></div>
<p>The data include several key variables</p>
<ul>
<li><code>abtrace1</code>: 1= if the respondent thought the ad was about race. 0= otherwise</li>
<li><code>condition2</code>: 1= respondent in the implicit condition. 2= respondent in one of four explicit racism conditions.</li>
<li><code>racresent</code>: a 0 to 1 numeric variable measuring racial resentment</li>
<li><code>oldfash</code>: a 0 to 1 numeric variable measuring “old-fashioned racism”</li>
<li><code>trumvote</code>: 1= respondent has vote preference for Trump 0=otherwise</li>
</ul>
<p><img src="images/bankstable1.png" style="width:75.0%" /></p>
<p>Let’s try to replicate column 5 in Table 1 using probit regression, as the authors do.</p>
<ul>
<li>Write down the equation for the regression.</li>
<li>Use <code>glm</code> to run the regression.</li>
<li>Compare the output to the table, column 5.</li>
</ul>
<details>
<summary>
Try on your own, then expand for the solution.
</summary>
<p>We are fitting a probit regression.</p>
<div class="sourceCode" id="cb341"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb341-1"><a href="week-3-tutorial.html#cb341-1" aria-hidden="true" tabindex="-1"></a><span class="do">## Column 5</span></span>
<span id="cb341-2"><a href="week-3-tutorial.html#cb341-2" aria-hidden="true" tabindex="-1"></a>fit.probit5 <span class="ot">&lt;-</span> <span class="fu">glm</span>(abtrace1 <span class="sc">~</span> <span class="fu">factor</span>(condition2)<span class="sc">*</span>racresent <span class="sc">+</span> <span class="fu">factor</span>(condition2)<span class="sc">*</span>oldfash,</span>
<span id="cb341-3"><a href="week-3-tutorial.html#cb341-3" aria-hidden="true" tabindex="-1"></a>                  <span class="at">data=</span>study, <span class="at">family=</span><span class="fu">binomial</span>(<span class="at">link =</span> <span class="st">&quot;probit&quot;</span>))</span>
<span id="cb341-4"><a href="week-3-tutorial.html#cb341-4" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(fit.probit5)</span></code></pre></div>
<pre><code>
Call:
glm(formula = abtrace1 ~ factor(condition2) * racresent + factor(condition2) * 
    oldfash, family = binomial(link = &quot;probit&quot;), data = study)

Deviance Residuals: 
    Min       1Q   Median       3Q      Max  
-2.2659  -0.9371  -0.5194   1.0015   2.0563  

Coefficients:
                              Estimate Std. Error z value Pr(&gt;|z|)    
(Intercept)                     0.6320     0.2431   2.600 0.009323 ** 
factor(condition2)2             0.9685     0.2797   3.462 0.000535 ***
racresent                      -1.9206     0.4174  -4.601  4.2e-06 ***
oldfash                         0.5265     0.3907   1.348 0.177772    
factor(condition2)2:racresent  -0.8513     0.4728  -1.801 0.071777 .  
factor(condition2)2:oldfash    -0.4197     0.4376  -0.959 0.337476    
---
Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1

(Dispersion parameter for binomial family taken to be 1)

    Null deviance: 1376.9  on 994  degrees of freedom
Residual deviance: 1148.7  on 989  degrees of freedom
  (25 observations deleted due to missingness)
AIC: 1160.7

Number of Fisher Scoring iterations: 4</code></pre>
<p>We can write the regression as:
<span class="math display">\[\begin{align*}
Pr(Y_i = 1 | X) &amp;= \\ \Phi(\alpha + \text{Explicit Politician Condition}_i*\beta_1 +\\ \text{Racial Resentment}_i *\beta_2 +\\
\text{Old Fashioned Racism}_i*\beta_3 +\\ \text{Explicit Politician Condition}_i*\text{Racial Resentment}_i*\beta_4 +\\
\text{Explicit Politician Condition}_i* \text{Old Fashioned Racism}_i*\beta_5)
\end{align*}\]</span></p>
<div class="sourceCode" id="cb343"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb343-1"><a href="week-3-tutorial.html#cb343-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(equatiomatic)</span>
<span id="cb343-2"><a href="week-3-tutorial.html#cb343-2" aria-hidden="true" tabindex="-1"></a><span class="fu">extract_eq</span>(fit.probit5, <span class="at">wrap =</span> <span class="cn">TRUE</span>, <span class="at">terms_per_line =</span> <span class="dv">3</span>)</span></code></pre></div>
<p><span class="math display">\[
\begin{aligned}
P( \operatorname{abtrace1} = \operatorname{1} ) &amp;= \Phi[\alpha + \beta_{1}(\operatorname{factor(condition2)}_{\operatorname{2}}) + \beta_{2}(\operatorname{racresent})\ + \\
&amp;\qquad\ \beta_{3}(\operatorname{oldfash}) + \beta_{4}(\operatorname{factor(condition2)}_{\operatorname{2}} \times \operatorname{racresent}) + \beta_{5}(\operatorname{factor(condition2)}_{\operatorname{2}} \times \operatorname{oldfash})]
\end{aligned}
\]</span></p>
</details>
<p>A few questions:</p>
<ul>
<li>How should we interpret the coefficients?</li>
<li>How do the interactions affect this interpretation?</li>
</ul>
</div>
<div id="numeric-optimization" class="section level3" number="6.7.2">
<h3><span class="header-section-number">6.7.2</span> Numeric Optimization</h3>
<p>Let’s repeat our replication of column 5, but this time, let’s use numeric optimization. We first need to make an X and Y matrix from our data. Because we have already run the models, let’s use a trick below:</p>
<div class="sourceCode" id="cb344"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb344-1"><a href="week-3-tutorial.html#cb344-1" aria-hidden="true" tabindex="-1"></a>X <span class="ot">&lt;-</span> <span class="fu">model.matrix</span>(fit.probit5)</span>
<span id="cb344-2"><a href="week-3-tutorial.html#cb344-2" aria-hidden="true" tabindex="-1"></a>Y <span class="ot">&lt;-</span> <span class="fu">as.matrix</span>(fit.probit5<span class="sc">$</span>y)</span></code></pre></div>
<p>The next thing we need to do is make a function for the log likelihood. Let’s recall the log likelihood for a Bernoulli random variable from a previous section:</p>
<p><span class="math display">\[\begin{align*}
\mathcal L( \pi | Y_i) &amp;= \underbrace{\pi^{y_i}(1 -\pi)^{(1-y_i)}}_\text{Likelihood for single observation}\\
\mathcal L( \pi | Y) &amp;= \underbrace{\prod_{i=1}^n\pi^{y_i}(1 -\pi)^{(1-y_i)}}_\text{Likelihood for all observations}\\
\ell( \pi | Y) &amp;= \underbrace{\sum_{i=1}^n\log \pi^{y_i}(1 -\pi)^{(1-y_i)}}_\text{Log likelihood}
\end{align*}\]</span></p>
<p>Now we just change the definition of <span class="math inline">\(\pi\)</span> to be the transformation for a probit, which is <span class="math inline">\(\Phi(X\beta)\)</span>. We code this up as a function below. Try to make the connection between the log likelihood equation above and the last line of the function. Note: in R, we can use <code>pnorm()</code> to express <span class="math inline">\(\Phi(X\beta)\)</span>, this is the CDF of the normal distribution.</p>
<div class="sourceCode" id="cb345"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb345-1"><a href="week-3-tutorial.html#cb345-1" aria-hidden="true" tabindex="-1"></a>llik.probit <span class="ot">&lt;-</span> <span class="cf">function</span>(par, Y, X){</span>
<span id="cb345-2"><a href="week-3-tutorial.html#cb345-2" aria-hidden="true" tabindex="-1"></a>  beta <span class="ot">&lt;-</span> <span class="fu">as.matrix</span>(par)</span>
<span id="cb345-3"><a href="week-3-tutorial.html#cb345-3" aria-hidden="true" tabindex="-1"></a>  link <span class="ot">&lt;-</span> <span class="fu">pnorm</span>(X <span class="sc">%*%</span> beta)</span>
<span id="cb345-4"><a href="week-3-tutorial.html#cb345-4" aria-hidden="true" tabindex="-1"></a>  like <span class="ot">&lt;-</span> <span class="fu">sum</span>(Y<span class="sc">*</span><span class="fu">log</span>(link) <span class="sc">+</span> (<span class="dv">1</span> <span class="sc">-</span> Y)<span class="sc">*</span><span class="fu">log</span>(<span class="dv">1</span> <span class="sc">-</span> link))</span>
<span id="cb345-5"><a href="week-3-tutorial.html#cb345-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">return</span>(like)</span>
<span id="cb345-6"><a href="week-3-tutorial.html#cb345-6" aria-hidden="true" tabindex="-1"></a>}</span></code></pre></div>
<p>Let’s generate some starting values for the optimization.</p>
<div class="sourceCode" id="cb346"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb346-1"><a href="week-3-tutorial.html#cb346-1" aria-hidden="true" tabindex="-1"></a><span class="do">## Starting values</span></span>
<span id="cb346-2"><a href="week-3-tutorial.html#cb346-2" aria-hidden="true" tabindex="-1"></a>ls.lm <span class="ot">&lt;-</span> <span class="fu">lm</span>(Y <span class="sc">~</span> X[, <span class="sc">-</span><span class="dv">1</span>]) </span>
<span id="cb346-3"><a href="week-3-tutorial.html#cb346-3" aria-hidden="true" tabindex="-1"></a>start.par <span class="ot">&lt;-</span> ls.lm<span class="sc">$</span>coef</span></code></pre></div>
<p>Finally, let’s use <code>optim</code> to find our parameter estimates.</p>
<div class="sourceCode" id="cb347"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb347-1"><a href="week-3-tutorial.html#cb347-1" aria-hidden="true" tabindex="-1"></a><span class="do">## optim()</span></span>
<span id="cb347-2"><a href="week-3-tutorial.html#cb347-2" aria-hidden="true" tabindex="-1"></a>out.opt <span class="ot">&lt;-</span> <span class="fu">optim</span>(start.par, llik.probit, <span class="at">Y=</span>Y,</span>
<span id="cb347-3"><a href="week-3-tutorial.html#cb347-3" aria-hidden="true" tabindex="-1"></a>                 <span class="at">X=</span>X, <span class="at">control=</span><span class="fu">list</span>(<span class="at">fnscale=</span><span class="sc">-</span><span class="dv">1</span>), <span class="at">method=</span><span class="st">&quot;BFGS&quot;</span>,</span>
<span id="cb347-4"><a href="week-3-tutorial.html#cb347-4" aria-hidden="true" tabindex="-1"></a>                 <span class="at">hessian =</span> <span class="cn">TRUE</span>)</span></code></pre></div>
<p>We can compare the estimates recovered from <code>glm</code> and <code>optim</code>.</p>
<div class="sourceCode" id="cb348"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb348-1"><a href="week-3-tutorial.html#cb348-1" aria-hidden="true" tabindex="-1"></a><span class="do">## Log likelihood</span></span>
<span id="cb348-2"><a href="week-3-tutorial.html#cb348-2" aria-hidden="true" tabindex="-1"></a><span class="fu">logLik</span>(fit.probit5)</span>
<span id="cb348-3"><a href="week-3-tutorial.html#cb348-3" aria-hidden="true" tabindex="-1"></a>out.opt<span class="sc">$</span>value</span></code></pre></div>
<pre><code>&#39;log Lik.&#39; -574.3267 (df=6)
[1] -574.3267</code></pre>
<div class="sourceCode" id="cb350"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb350-1"><a href="week-3-tutorial.html#cb350-1" aria-hidden="true" tabindex="-1"></a><span class="do">## Coefficients</span></span>
<span id="cb350-2"><a href="week-3-tutorial.html#cb350-2" aria-hidden="true" tabindex="-1"></a><span class="fu">cbind</span>(<span class="fu">round</span>(<span class="fu">coef</span>(fit.probit5), <span class="at">digits=</span><span class="dv">4</span>),</span>
<span id="cb350-3"><a href="week-3-tutorial.html#cb350-3" aria-hidden="true" tabindex="-1"></a><span class="fu">round</span>(out.opt<span class="sc">$</span>par, <span class="at">digits =</span> <span class="dv">4</span>))</span></code></pre></div>
<pre><code>                                 [,1]    [,2]
(Intercept)                    0.6320  0.6321
factor(condition2)2            0.9685  0.9684
racresent                     -1.9206 -1.9207
oldfash                        0.5265  0.5265
factor(condition2)2:racresent -0.8513 -0.8512
factor(condition2)2:oldfash   -0.4197 -0.4196</code></pre>
<p>How could we get the standard errors?</p>
</div>
<div id="predicted-probabilities" class="section level3" number="6.7.3">
<h3><span class="header-section-number">6.7.3</span> Predicted Probabilities</h3>
<p>One thing we could do for our interpretations is to push this further to generate “quantities of interest.”</p>
<p><img src="images/abtracefig.png" style="width:70.0%" /></p>
<p>We will do one example of this but will talk in more detail about this next week. Let’s generate predicted probabilities for thinking the ad is about race across levels of racial resentment in the sample, for people in the implicit and explicit conditions. For this example, we are going to hold “old-fashioned racism” at its mean value. This is slightly different from what the authors do but should generate similar results. The authors hold old-fashioned racism at its “observed values.”</p>
<p>We can rely on the <code>predict</code> function like we did with OLS, but here, we need to set <code>type = response</code> to put the results on the response scale instead of the scale of the linear predictor. What this does is apply our function <span class="math inline">\(\Phi(\mathbf{x_i}&#39; \hat \beta)\)</span> for our designated values of <span class="math inline">\(X\)</span> and estimates for <span class="math inline">\(\hat \beta\)</span>.</p>
<div class="sourceCode" id="cb352"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb352-1"><a href="week-3-tutorial.html#cb352-1" aria-hidden="true" tabindex="-1"></a>predvals.imp <span class="ot">&lt;-</span> <span class="fu">predict</span>(fit.probit5, <span class="at">newdata =</span> <span class="fu">data.frame</span>(<span class="at">condition2=</span><span class="dv">1</span>, </span>
<span id="cb352-2"><a href="week-3-tutorial.html#cb352-2" aria-hidden="true" tabindex="-1"></a>                                                         <span class="at">racresent =</span> <span class="fu">seq</span>(<span class="dv">0</span>, <span class="dv">1</span>, .<span class="dv">0625</span>),</span>
<span id="cb352-3"><a href="week-3-tutorial.html#cb352-3" aria-hidden="true" tabindex="-1"></a>                                         <span class="at">oldfash =</span> <span class="fu">mean</span>(study<span class="sc">$</span>oldfash, <span class="at">na.rm=</span>T)),</span>
<span id="cb352-4"><a href="week-3-tutorial.html#cb352-4" aria-hidden="true" tabindex="-1"></a>                    <span class="at">type=</span><span class="st">&quot;response&quot;</span>)</span>
<span id="cb352-5"><a href="week-3-tutorial.html#cb352-5" aria-hidden="true" tabindex="-1"></a>predvals.exp <span class="ot">&lt;-</span> <span class="fu">predict</span>(fit.probit5, <span class="at">newdata =</span> <span class="fu">data.frame</span>(<span class="at">condition2=</span><span class="dv">2</span>,</span>
<span id="cb352-6"><a href="week-3-tutorial.html#cb352-6" aria-hidden="true" tabindex="-1"></a>                                                         <span class="at">racresent =</span> <span class="fu">seq</span>(<span class="dv">0</span>, <span class="dv">1</span>,.<span class="dv">0625</span>),</span>
<span id="cb352-7"><a href="week-3-tutorial.html#cb352-7" aria-hidden="true" tabindex="-1"></a>                                         <span class="at">oldfash =</span> <span class="fu">mean</span>(study<span class="sc">$</span>oldfash, <span class="at">na.rm=</span>T)),</span>
<span id="cb352-8"><a href="week-3-tutorial.html#cb352-8" aria-hidden="true" tabindex="-1"></a>                    <span class="at">type=</span><span class="st">&quot;response&quot;</span>)</span>
<span id="cb352-9"><a href="week-3-tutorial.html#cb352-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb352-10"><a href="week-3-tutorial.html#cb352-10" aria-hidden="true" tabindex="-1"></a><span class="do">## Plot results</span></span>
<span id="cb352-11"><a href="week-3-tutorial.html#cb352-11" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(<span class="at">x=</span><span class="fu">seq</span>(<span class="dv">0</span>, <span class="dv">1</span>, .<span class="dv">0625</span>), <span class="at">y=</span>predvals.imp, <span class="at">type=</span><span class="st">&quot;l&quot;</span>,</span>
<span id="cb352-12"><a href="week-3-tutorial.html#cb352-12" aria-hidden="true" tabindex="-1"></a>     <span class="at">ylim =</span> <span class="fu">c</span>(<span class="dv">0</span>, <span class="dv">1</span>), <span class="at">lty=</span><span class="dv">2</span>,</span>
<span id="cb352-13"><a href="week-3-tutorial.html#cb352-13" aria-hidden="true" tabindex="-1"></a>     <span class="at">ylab =</span> <span class="st">&quot;Predicted Probability&quot;</span>,</span>
<span id="cb352-14"><a href="week-3-tutorial.html#cb352-14" aria-hidden="true" tabindex="-1"></a>     <span class="at">xlab =</span> <span class="st">&quot;Racial Resentment&quot;</span>,</span>
<span id="cb352-15"><a href="week-3-tutorial.html#cb352-15" aria-hidden="true" tabindex="-1"></a>     <span class="at">main =</span> <span class="st">&quot;Predicted Probability of Viewing the Ad as about Race&quot;</span>,</span>
<span id="cb352-16"><a href="week-3-tutorial.html#cb352-16" aria-hidden="true" tabindex="-1"></a>     <span class="at">cex.main =</span> .<span class="dv">7</span>)</span>
<span id="cb352-17"><a href="week-3-tutorial.html#cb352-17" aria-hidden="true" tabindex="-1"></a><span class="fu">legend</span>(<span class="st">&quot;bottomleft&quot;</span>, <span class="at">lty=</span> <span class="fu">c</span>(<span class="dv">2</span>,<span class="dv">1</span>), <span class="fu">c</span>(<span class="st">&quot;Implicit&quot;</span>, <span class="st">&quot;Explicit&quot;</span>))</span>
<span id="cb352-18"><a href="week-3-tutorial.html#cb352-18" aria-hidden="true" tabindex="-1"></a><span class="fu">points</span>(<span class="at">x=</span><span class="fu">seq</span>(<span class="dv">0</span>, <span class="dv">1</span>, .<span class="dv">0625</span>), <span class="at">y=</span>predvals.exp, <span class="at">type=</span><span class="st">&quot;l&quot;</span>)</span></code></pre></div>
<p><img src="mlebookout_files/figure-html/unnamed-chunk-160-1.svg" width="672" /></p>
<p><em>Additional Questions</em></p>
<ul>
<li>For extra practice, you can try replicating column 4 in the model.</li>
<li>You can also try replicating the results in the figure with a logit model. Are the predicted probabilities similar?</li>
</ul>

</div>
</div>
<!-- </div> -->
            </section>

          </div>
        </div>
      </div>
<a href="linear-probability-models.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="qoi.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": null,
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
